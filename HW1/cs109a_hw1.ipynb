{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: I consulted on the 'philisophical problems' about the dataset, biases, etc. with Oluwatosin Alliyu but we wrote all of our code separately so we are not submitting as a group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
    "    color: black;\"> <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science </h1>\n",
    "\n",
    "## Homework 1: Data Collection, Parsing, and Quick Analyses\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner<br/>\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2020-CS109A/master/themes/static/css/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "## Overview \n",
    "\n",
    "In this homework, your goal is to learn how to acquire, parse, clean, and analyze data. Toward this goal, we will address certain question about COVID, and you will scrape data directly from a website. For the remainder of the semester, we will provide you data files directly; however, since real-world problems often require gathering information from a variety of sources, including the Internet, web scraping is a highly useful skill to have.\n",
    "\n",
    "### Instructions\n",
    "- To submit your assignment, follow the instructions given in Canvas.\n",
    "\n",
    "### Learning Objectives\n",
    "- Get started using Jupyter Notebooks, which are incredibly popular, powerful, and will be our medium of programming for the duration of CS109A and CS109B.\n",
    "- Become familiar with how to access and use data from various sources (i.e., web scraping and directly from files).\n",
    "- Gain experience with data exploration and simple analysis.\n",
    "- Become comfortable with PANDAS as a means of storing and working with data.\n",
    "- Reflect on what further analysis you may wish to do with this data. For example, given the material we've covered so far, what *more* do you wish you had the ability to do (e.g., modelling, prediction, etc). That is, think about questions you may have about the data, and try to imagine what types of tools you might need to help answer your questions.\n",
    "\n",
    "### Notes\n",
    "- Exercise **responsible scraping**. Web servers can become slow or unresponsive if they receive too many requests from the same source in a short amount of time. In your code, use a delay of 2 seconds between requests. This helps to not get blocked by the target website -- imagine how frustrating it would be to have this occur. Section 1 of this homework involves saving the scraped web pages to your local machine. Thus, after completing Section 1, you do not need to re-scrape any of the pages, unless you wish to occasionally grab the latest data. \n",
    "\n",
    "- Web scraping requests can take several minutes. This is another reason why you should not wait until the last minute to do this homework.\n",
    "- As you run a Jupyter Notebook, it maintains a running state of memory. Thus, the order in which you run cells matters and plays a crucial role; it can be easy to make mistakes based on *when* you run different cells as you develop and test your code. **Before submitting every Jupyter Notebook homework assignment, be sure to restart your Jupyter Notebook and run the entire notebook from scratch, all at once (i.e., \"Kernel -> Restart & Run All\")**\n",
    "- We will be working with COVID data. COVID has impacted everyone in the world, and naturally some people have been greatly more affected than others. We, the teaching staff, are sensitive to this, empathize, and understand that working with COVID data may be unsettling to some. We apologize for any discomfort this may cause. Our intent with this assignment is purely pedagogical, and we'd like to remind students that data science and machine learning can be used to provide insights that can be used for good and invoke change. Toward this goal, parts of the homework are intended to shed light on the unfortunate, widespread inequality that exists. So, while this data may be unsettling, our aim is for the learned skills addressed here -- and in all future assignments -- to provide you with knowledge and confidence to do good work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1. Obtaining Data (17 points)\n",
    "\n",
    "For any given situation or scenario that we wish to understand, we will rely on having relevant data. Here, we are interested in the degree to which the SARS-CoV-2 virus has affected United States citizens (SARS-CoV-2 is the virus that causes the COVID-19 disease). The Centers for Disease Control and Prevention (CDC) provides relevant data from USAFacts.org that includes the number of confirmed COVID-19 cases on a per-county basis. Visit https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/. At the bottom of the web page, in a blue table, you should see a list of every state, each of which has its own web page.\n",
    "\n",
    "In this exercise, we will focus on automating the downloading of each state's data (via ``Requests``). First, as we will do for every Jupyter Notebook, let's import necessary packages that we will use throughout the notebook (i.e., run the cell below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NOTE: files will be saved to this directory, so you need to ensure\n",
    "# that it exists on your system first (it should be visible from the\n",
    "# directory of where you are running this Notebook file)\n",
    "# i.e.,\n",
    "# >> ls\n",
    "# cs109a_hw1_student.ipynb\n",
    "# election2016_by_county.csv\n",
    "# data/\n",
    "state_dir = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# we define this for convenience, as every state's url begins with this prefix\n",
    "base_url = 'https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 1.1 [1 pt]: Fetching Website data via Requests</b>\n",
    "\n",
    "Fetch the web page located at `base_url` and save the request's returned object (a Response object) to a variable named `home_page`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "home_page = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 1.2 [2 pts]:</b> In the cell below:\n",
    "    \n",
    "- Write a line of code that prints to the screen the status of `home_page` (the web page's returned object). You should receive a code of 200 if the request was successful; then,\n",
    "\n",
    "- Write code that prints the entire contents of `home_page`</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print('Status Code: {}'.format(home_page.status_code))\n",
    "print('Webpage Text')\n",
    "print(home_page.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 1.3 [1 pt]:</b>\n",
    "    \n",
    "In the cell below, create a new BeautifulSoup object that parses the `home_page` as an HTML document (can be done with 1 line of code)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(home_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 1.4 [8 pts]:</b>\n",
    "    \n",
    "In the cell below, write code that uses the BeautifulSoup object to parse through the home page in order to extract the link for every state. Feel free to use Regular Expressions, in conjunction with any BeautifulSoup parsing. Specifically, the goal is to populate the `state_urls` dictionary by setting each key to be the state name and the value to be the full URL. When complete, there will be 51 keys (50 states + 1 for DC).\n",
    "\n",
    "### AS A CRITICAL EXAMPLE:###\n",
    "Within `state_urls`, one of your <key, value> pairs should be:\n",
    "\n",
    "``\"District of Columbia\" : \"https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/state/district-of-columbia\"``\n",
    "\n",
    "The casing here is **incredibly** important because later, in Exercise 4, you will merge your data with another dataset that has casing of this form. Thus, our key here should be `District of Columbia` and not `District Of Columbia` or `district-of-columbia`.\n",
    "\n",
    "\n",
    "**NOTES:**\n",
    "- There are _many_ solutions, but you may find it easiest to use Regular Expression(s)\n",
    "- Pay attention to the casing example above, so that your later Exercises go smoothly. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "state_urls = {}\n",
    "\n",
    "#find each link set in the html file\n",
    "for link in soup.findAll('a'):\n",
    "    \n",
    "    #get the url\n",
    "    url = link.get('href')\n",
    "    \n",
    "    #check if the url follows the base format\n",
    "    if re.search(base_url[20:], url):\n",
    "        \n",
    "        #if so pull out the state name\n",
    "        match = re.search(r\"state/(.+)\", url)\n",
    "        state_url = base_url + match.group(0)\n",
    "        \n",
    "        state = link.text\n",
    "        \n",
    "        #add to the dictionary\n",
    "        state_urls[state] = state_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below to help ensure your formatting is correct and has 51 <key, value> pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "if len(state_urls.keys()) != 51 or \\\n",
    "state_urls[\"District of Columbia\"] != \"https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/state/district-of-columbia\":\n",
    "    print(\"** 1.4 is incorrect\")\n",
    "else:\n",
    "    print(\"** 1.4 might be correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We wish to use the data without having to re-download it every time. So, let's save each webpage to our local hard drive. **NOTE: It's probably okay to download all of the state web pages a few times a day, but it's safer to keep it to a minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 1.5 [5 pts]:</b>\n",
    "    \n",
    "In the cell below, we will iterate through all <key, value> items in `state_urls`. Your job is to make a web request for each URL and save the **contents** out to a file on your hard drive (use `state_dir` as the prefix to the path.) \n",
    "\n",
    "**NOTES:**\n",
    "- Leave the 2 second pause\n",
    "- You should be saving to a file the actual content of the webpage, not a BeautifulSoup object. That is, you should be able to open the saved files in an editor and see the HTML code, just as you could if you were to view the webpage in your browser and click 'View Page Source'.\n",
    "- See [official Python documentation](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) for details on how to read/write files to disk\n",
    "- You should have saved 51 different files to your hard drive.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1.5 (4 pts) -- save each webpage to disk\n",
    "for state, url in state_urls.items():\n",
    "    \n",
    "    with open(state_dir + state + '.html', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "    \n",
    "    sleep(2) # LEAVE THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. Loading and Exploring Data (22 pts)\n",
    "Now, let's actually use the data! Fortunately, it's saved to our local machine, so we don't need to re-crawl the data every time we wish to access it. We want you to understand that PANDAS is a library of useful data structures and operations, but we also wish to remind you that it isn't magic and it isn't the _only_ way to do Data Science; it's just a tool to help, and you could do the same operations without PANDAS. Thus, here we ask you to perform a few operations without using PANDAS, and then in Exercise 3 we will use PANDAS.\n",
    "\n",
    "**Terminology Notice:** In the United States, every state is comprised of many **counties.** You can think of a **county** as being a pretty large district. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "First, run the cell below to construct `state_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "state_info = [(state, state_dir + state) for state in state_urls.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 2.1 [10 pts]: Parsing and storing data</b>\n",
    "    \n",
    "Complete the `load_covid_data()` function, which:\n",
    "\n",
    "- Takes as input `state_info`, which is a list of tuples: (state name, path to the corresponding file)\n",
    "- Parses the contents of the file and extracts for **each county**:\n",
    "    - \\# of confirmed cases (total)\n",
    "    - \\# of deaths\n",
    "    - \\# of confirmed cases (per 100k)\n",
    "- Stores in a **non-PANDAS** data structure named `covid_data` the above 3 pieces of data, **for every county across every state**\n",
    "- Returns `county_counts`\n",
    "    <font color='blue'>\n",
    "\n",
    "**NOTES:**\n",
    "- To be clear, as of September 7, 2020, the webpage for Alabama currently lists 67 counties. District of Columbia has 1 county, and Wyoming has 23. Here we are asking you to store in `covid_data` *all counties* across every state. So, later, if we were wished to access just Wyoming's information, you could easily retrieve such for each of its 23 counties, or the info for any of the 67 counties in Alabama. \n",
    "- `covid_data` **must not be a PANDAS data structure;** it must use a combination of lists and/or dictionaries. It's up to you to decide how to organize this, e.g., a lists of lists of lists, or a list of dictionaries, or a dictionary of dictionaries, or a dictionary of lists of lists, etc. A guiding decision should be ease of access for computing basic stats (Exercises 2.2, 2.3, and 2.4)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# parses all county-level COVID data from the\n",
    "# passed-in list of (state, filepath) tuples \n",
    "def load_covid_data(state_info):\n",
    "    '''\n",
    "    input: list of tuples of type (state name, /path/state name)\n",
    "    output: dictionary of type \n",
    "                {State:{\"Counties\": list, \n",
    "                        \"Cases\": list,\n",
    "                        \"Deaths\": list,\n",
    "                        \"Cases (Per 100K)\": list}}\n",
    "            with one entry for each state, and the lists each sorted\n",
    "            by county\n",
    "    '''\n",
    "    \n",
    "    def load_state_data(state_tuple):\n",
    "        '''\n",
    "        input: a tuple from the state_info\n",
    "        output: an entry to the output dictionary\n",
    "        \n",
    "        Includes an assert statement to make sure that the \n",
    "        entries in the table are all the same length\n",
    "        '''\n",
    "        counties = []\n",
    "        cases = []\n",
    "        deaths = []\n",
    "        cases_norm = []\n",
    "\n",
    "        with open(state_tuple[1] + '.html') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        state = state_tuple[0]\n",
    "        \n",
    "        #find the counties by looking for links\n",
    "        for link in soup.find_all('a'):\n",
    "            url = link.get('href')\n",
    "            \n",
    "            #all county links look the same\n",
    "            if re.search(base_url[20:], url):\n",
    "                match = re.search(\"/state/.+/county/(.+)\", url)\n",
    "                county = link.text\n",
    "                counties.append(county)\n",
    "                \n",
    "        #find table entries by looking for a tag\n",
    "        table = [cases, deaths, cases_norm]\n",
    "        counter = 0\n",
    "        for entry in soup.find_all('td'):\n",
    "            if counter%3 == 2:\n",
    "                number = float(entry.text.replace(',',''))\n",
    "            else:\n",
    "                number = int(entry.text.replace(',',''))\n",
    "            table[counter % 3].append(number)\n",
    "            counter += 1 \n",
    "\n",
    "        county_counts = {\"Counties\": counties, \n",
    "                        \"Cases\": cases,\n",
    "                        \"Deaths\": deaths,\n",
    "                        \"Cases (Per 100K)\": cases_norm}\n",
    "        \n",
    "        #check that everything is the same length\n",
    "        assert (len(counties) == \n",
    "            len(cases) == \n",
    "            len(deaths) == \n",
    "            len(cases_norm)), (\"The table lengths for \" + state +\n",
    "                                \" do not all match up!\")\n",
    "        \n",
    "        return county_counts\n",
    "    \n",
    "    covid_data = {}\n",
    "\n",
    "    for state_tuple in state_info:\n",
    "        covid_data[state_tuple[0]] = load_state_data(state_tuple)\n",
    "\n",
    "    return covid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "covid_data = load_covid_data(state_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 2.2 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_county_stats()` function, which calculates:\n",
    "1. The single county (and the state to which it belongs) that has the **lowest rate** of COVID cases per 100k people\n",
    "2. The single county (and the state to which it belongs) that has the **highest rate** of COVID cases per 100k people\n",
    "\n",
    "**NOTES:**\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide\n",
    "- These values you report should be Floating point numbers (e.g., 3.4), not Integers (e.g., 3).\n",
    "- If there are ties, return any of the tied counties\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_county_stats(covid_data):\n",
    "    highest = 0\n",
    "    lowest = 100000000\n",
    "    \n",
    "    for state in covid_data:\n",
    "        stat = covid_data[state]['Cases (Per 100K)']\n",
    "        max_stat = max(stat)\n",
    "        min_stat = min(stat)\n",
    "        if max_stat > highest:\n",
    "            highest = max_stat\n",
    "            highest_county_index = stat.index(max_stat)\n",
    "            highest_county = covid_data[state]['Counties'][highest_county_index]\n",
    "        \n",
    "        if min_stat < lowest:\n",
    "            lowest = min_stat\n",
    "            lowest_county_index = stat.index(min_stat)\n",
    "            lowest_county = covid_data[state]['Counties'][lowest_county_index]\n",
    "        \n",
    "    print(lowest_county + \" has the lowest rate of confirmed COVID cases: \" + str(lowest) + \" per 100k\")\n",
    "    print(highest_county + \" has the highest rate of confirmed COVID cases: \" + str(highest) + \" per 100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_county_stats(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 2.3 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deaths()` function, which calculates:\n",
    "1. The state that has the **lowest number** of deaths\n",
    "2. The state that has the **highest number** of deaths\n",
    "\n",
    "**NOTES:**\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- These values you report should be Integers, not Floating point numbers.\n",
    "- If there are ties, return any of the tied counties\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_state_deaths(covid_data):\n",
    "    highest = 0\n",
    "    lowest = 10000000\n",
    "    for state in covid_data:\n",
    "        stat = sum(covid_data[state]['Deaths'])\n",
    "        if stat > highest:\n",
    "            highest = stat\n",
    "            highest_state = state\n",
    "        \n",
    "        if stat < lowest:\n",
    "            lowest = stat\n",
    "            lowest_state = state\n",
    " \n",
    "    print(lowest_state + \" has the fewest COVID deaths: \" + str(lowest))\n",
    "    print(highest_state + \" has the most COVID deaths: \" + str(highest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_state_deaths(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 2.4 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deathrate()` function, which calculates:\n",
    "1. The state that has the **lowest rate** of deaths based on its entire population\n",
    "2. The state that has the **highest rate** of deaths based on its entire population\n",
    "\n",
    "**NOTES:**\n",
    "- To calculate a state's population, we are asserting that is sufficient to sum the population over all counties, and that each county's population can be calculated simply from the data fields stored within `covid_data`.\n",
    "- **If a county has reported 0 COVID cases,** then we should ignore this county as we estimate its county population. Thus, that county would contribute 0 to its state population total.\n",
    "- Round your results to the a single person (e.g., \"1 out of every 2703 people has died\" not 2703.4)\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_state_deathrate(covid_data):\n",
    "    highest = 0\n",
    "    lowest = 10000000\n",
    "    for state in covid_data:\n",
    "        base = covid_data[state]\n",
    "        state_pop = 0\n",
    "        state_deaths = 0\n",
    "        i = 0\n",
    "        \n",
    "        for i in range(len(covid_data[state][\"Counties\"])):\n",
    "            if base[\"Cases (Per 100K)\"][i] != 0:\n",
    "                county_pop = base[\"Cases\"][i]/base[\"Cases (Per 100K)\"][i] * 100000\n",
    "                state_pop += county_pop\n",
    "                state_deaths += base[\"Deaths\"][i]\n",
    "        \n",
    "        death_rate = state_deaths/state_pop\n",
    "        stat = death_rate\n",
    "        \n",
    "        if stat > highest:\n",
    "            highest = stat\n",
    "            highest_state = state\n",
    "        \n",
    "        if stat < lowest:\n",
    "            lowest = stat\n",
    "            lowest_state = state\n",
    "    \n",
    "    print(lowest_state + \" has the lowest COVID death rate; 1 out of every \" + str(int(1/lowest)) + \" people has died\")\n",
    "    print(highest_state + \" has the highest COVID death rate; 1 out of every \" + str(int(1/highest)) + \" people has died\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_state_deathrate(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3. PANDAS (36 pts)\n",
    "What if we wanted to observe more than just the single-most extreme counties and states? What if we wanted to inspect all states, after having sorted the data by some feature? As you saw in the above exercises, doing the most basic analytics is possible, but it can quickly become cumbersome. As we learned in class, PANDAS is a great library that provides data structures that are highly useful for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 3.1 [10 pts]: Converting to PANDAS</b>\n",
    "\n",
    "In Exercise 2, we worked with `covid_data`, which is comprises of some combination of lists and/or dictionaries.\n",
    "\n",
    "Complete the `convert_to_pandas()` function, which converts `covid_data` to a PANDAS DataFrame, whereby:\n",
    "- Each row corresponds to a unique county\n",
    "- The 5 columns are:\n",
    "    - county\n",
    "    - state\n",
    "    - \\# total covid cases (Integer)\n",
    "    - \\# covid cases per 100k (Integer)\n",
    "    - \\# covid deaths (Integer)\n",
    "- The columns should be titled **exactly** as listed above\n",
    "\n",
    "**NOTE:**\n",
    "- If there exists multiple counties with the same name, each of which belonging to a different state, then there should be a distinct row for each.\n",
    "- The 3 columns that correspond to COVID counts should all be Integers (e.g., 1498), not Floating point digits (e.g., 1498.0)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def convert_to_pandas(covid_data):\n",
    "    neat_data = {}\n",
    "    index = 0\n",
    "    for state in covid_data:\n",
    "        d = covid_data[state]\n",
    "        for i in range(len(d[\"Counties\"])):\n",
    "            neat_data[index] = {'county': d[\"Counties\"][i],\n",
    "                               'state': state,\n",
    "                               '# total covid cases': d[\"Cases\"][i],\n",
    "                               '# covid cases per 100k': d[\"Cases (Per 100K)\"][i],\n",
    "                               '# covid deaths': d[\"Deaths\"][i]}\n",
    "            index += 1\n",
    "    \n",
    "    covid_df = pd.DataFrame(neat_data).T\n",
    "    covid_df = covid_df.astype({'county': object,\n",
    "                               'state': object,\n",
    "                               '# total covid cases': int,\n",
    "                               '# covid cases per 100k': float,\n",
    "                               '# covid deaths': int})\n",
    "    return covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "covid_df = convert_to_pandas(covid_data)\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 3.2 [5 pts]: Simple analytics</b>\n",
    "\n",
    "Complete the `calculate_county_stats2()` function, **which should obtain identical information as problem 2.2, but now using the PANDAS `covid_df` DataFrame.**\n",
    "\n",
    "That is, it should calculates:\n",
    "1. the single county (and the state to which it belongs) that has the **lowest rate** of COVID cases per 100k people\n",
    "2. the single county (and the state to which it belongs) that has the **highest rate** of COVID cases per 100k people\n",
    "\n",
    "**NOTES:**\n",
    "- If there are ties, return any of the tied counties\n",
    "- Place your resulting variables within the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- The values you report should be Floating point numbers (e.g., 3.4), not Integers (e.g., 3).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_county_stats2(covid_df):\n",
    "    column = '# covid cases per 100k'\n",
    "    \n",
    "    lowest = covid_df[covid_df[column] == min(covid_df[column])].iloc[0]\n",
    "    highest = covid_df[covid_df[column] == max(covid_df[column])].iloc[0]\n",
    "\n",
    "    print(lowest['county'] + \" (\" + lowest['state'] + \") has the lowest rate of confirmed COVID cases: \" + str(lowest[column]) + \" per 100k\")\n",
    "    print(highest['county'] + \" (\" + highest['state'] + \") has the highest rate of confirmed COVID cases: \" + str(highest[column]) + \" per 100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_county_stats2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 3.3 [5 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deaths2()` function, **which should obtain identical information as problem 2.3, but now using the PANDAS `covid_df` DataFrame.**\n",
    "1. the state that has the **lowest number** of deaths\n",
    "2. the state that has the **highest number** of deaths\n",
    "\n",
    "**NOTES:**\n",
    "- If there are ties, return any of the tied counties\n",
    "- Place your resulting variables within the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- The values you report should be Integers, not Floating point numbers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_state_deaths2(covid_df):\n",
    "    column = '# covid deaths'\n",
    "    \n",
    "    group = covid_df.groupby(by='state').sum()\n",
    "    low_state = group[group[column] == min(group[column])].head(1).index[0]\n",
    "    high_state = group[group[column] == max(group[column])].head(1).index[0]\n",
    "    lowest = min(group[column])\n",
    "    highest = max(group[column])\n",
    "    print(low_state + \" has the fewest COVID deaths: \" + str(lowest))\n",
    "    print(high_state + \" has the most COVID deaths: \" + str(highest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_state_deaths2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 3.4 [5 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deathrate2()` function, **which should obtain identical information as problem 2.4, but now using the PANDAS `covid_df` DataFrame.**\n",
    "\n",
    "1. The state that has the **lowest rate** of deaths based on its entire population\n",
    "2. The state that has the **highest rate** of deaths based on its entire population\n",
    "\n",
    "**NOTES:**\n",
    "- Just as in, 2.4, to calculate a state's population, we are asserting that is sufficient to sum the population over all counties -- and that each county's population can be calculated simply from the data fields stored within `covid_data`.\n",
    "- Just as in 2.4, counties with 0 COVID cases should contibute 0 to the total population of the state.\n",
    "- Round your results to the a single person (e.g., \"1 out of every 2703 people has died\" not 2703.4)\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def calculate_state_deathrate2(covid_df):\n",
    "    covid_df_no0 = covid_df[covid_df['# total covid cases'] != 0]\n",
    "    covid_df_no0.loc[:,'population'] = covid_df_no0['# total covid cases']/covid_df_no0[\"# covid cases per 100k\"]*100000\n",
    "    states = covid_df_no0.groupby(by = 'state').sum()\n",
    "    states['death rate'] = states['population']/states['# covid deaths']\n",
    "    \n",
    "    lowest = states[states['death rate'] == max(states['death rate'])].iloc[0]\n",
    "    highest = states[states['death rate'] == min(states['death rate'])].iloc[0]\n",
    "\n",
    "    print(lowest.name + \" has the lowest COVID death rate; 1 out of every \" + str(int(lowest['death rate'])) + \" people has died\")\n",
    "    print(highest.name + \" has the highest COVID death rate; 1 out of every \" + str(int(highest['death rate'])) + \" people has died\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "calculate_state_deathrate2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "These are highly alarming and tragic statistics, and doing calculations like this can really put the severity of the virus into a grounded perspective. In order to perfectly understand the virus and its spread, everyone would be tested and we would have contact tracing. Without getting into socio-political issues, our point is that (1) we wish to better understand the virus' effects; (2) naturally, any real-world data is messy, and thus we will never have _perfect_ data.\n",
    "\n",
    "\n",
    "Let's now attempt to understand _some_ of the uncertainty around our COVID data. It's reasonable to believe that the # of COVID deaths is fairly reliable. That is, there are inevitably some false negatives -- people who died of COVID but were not accounted for, as other conditions were listed as the cause. However, the number of false positives is probably minimal -- if someone was denoted as dying from COVID, it's probably true. It's also the case that every disease has a mortality rate. For example, if 1,000 randomly-selected people contracted COVID, $N\\%$ of them will die. We'd imagine that this percentage should be pretty constant throughout all people in the United States. Of course, we can think of reasons for this rate to not be perfectly consistent, as some people are at higher risk (e.g., older folks, people with pre-existing conditions, etc). Yet, we can imagine that this natural *variance* in the population to be fairly uniform throughout the USA at large. To this end, if all counties were equal in their **testing**, we ought to see a consistent ratio between: (a) the # of people who died from COVID; and (b) the # of people who tested positive for COVID. Within the medical domain, this ratio is referred to as the `case_fatality_rate`. For example, if 750 people tested positive for COVID, and 75 of those people died, then our `case_fatality_rate` would be 0.1 (meaning 10%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 3.5 [5 pts]: Further analytics</b>\n",
    "    \n",
    "Complete the `add_death_stats()` function below, which should add 2 new columns:\n",
    "- `case_fatality_rate` and\n",
    "- `# covid deaths per 100k`\n",
    "\n",
    "And return the updated DataFrame **sorted by case_fatality_rate in ascending order** \n",
    "\n",
    "**NOTES:**\n",
    "\n",
    "- `add_death_stats()` should return a new DataFrame that has 8 columns:\n",
    "    - county\n",
    "    - state\n",
    "    - population\n",
    "    - \\# total covid cases\n",
    "    - \\# covid cases per 100k\n",
    "    - \\# total covid deaths\n",
    "    - \\# covid deaths per 100k\n",
    "    - case_fatality_rate\n",
    "- DataFrame should be sorted by `case_fatality_rate` in ascending order\n",
    "- Again, the values for `case_fatality_rate` should be < 1. A value of 1 would mean that 100% of people who tested positive for COVID also died.\n",
    "- `# covid deaths per 100k` is simply defined as the # of COVID deaths for every 100,000 people. We calculate this on a per-county basis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def add_death_stats(covid_df):\n",
    "    # get rid of counties with no cases as we cannot estimate their population\n",
    "    covid_df = covid_df[covid_df['# total covid cases'] != 0]\n",
    "    \n",
    "    d = covid_df\n",
    "    \n",
    "    d.loc[:,'population'] = d['# total covid cases']/d[\"# covid cases per 100k\"]*100000\n",
    "    d.loc[:,'case_fatality_rate'] = d['# covid deaths']/d['# total covid cases']\n",
    "    d.loc[:,'# covid deaths per 100k'] = d['# covid deaths']/(d['population']/100000)\n",
    "    \n",
    "    #sort code by ascending fatality\n",
    "    d.sort_values(by = 'case_fatality_rate', inplace = True)\n",
    "    return covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "covid_updated = add_death_stats(covid_df)\n",
    "covid_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Exercise 3.6 [6 pts]: Reflection:</b> Data Analysis allows us to better understand a system or scenario.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 3.6: Q1 (2  of 6 pts)</b>\n",
    "    \n",
    "Having looked at the results from Exercises 3.3, 3.4, and 3.5, what are some trends you've noticed and any conclusions you have? (2-3 sentences)?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the statistic we are looking at - case fatality, total deaths, case rate, death rate - there are huge variations accross the country, with some areas being affected much more than other areas. This leads me to believe that there are other factors that render our earlier assumption that rates such as fatality or death rate should be consistent accross locations incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 3.6: Q2 (2 of 6 pts)</b>\n",
    "    \n",
    "Having looked at the results from Exercise 3.5 (i.e., `covid_updated` DataFrame), do you think the original data is reliable and accurate? Are there any potential biases that you're aware of or concerned about? Please explain (3-5 sentences).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We threw out all of the counties that did not have any cases reported, which will certainly bias our answers. Instead it would be a better idea to get the county populations from another source instead of using the cases per 100k to calculate the population\n",
    "\n",
    "I do not think that our calculation of case fatality rate makes sense to compare accross counties because we know for a fact that not all counties are conducting testing at the same rate. I think death/population is a much better number to consider. Similarly, I think the 'total deaths' is a much more reliable number to consider than 'total cases'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 3.6: Q3 (1 of 6 pts)</b>\n",
    "    \n",
    "If a county has 15 confirmed deaths, how many cases would you expect? What would you expect its population to be? Explain why (1-2 sentences in total)?\n",
    "\n",
    "**NOTE:** For this question, we aren't evaluating the accuracy of your answer but your thought-process and reasoning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check if the stats on average deaths per 100K and fatality rate differ significantly between all conties and counties with about 15 deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all counties\n",
    "\n",
    "covid_updated.loc[:, ['case_fatality_rate', '# covid deaths per 100k']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = covid_updated[\n",
    "    (covid_updated['# covid deaths']<18) & \n",
    "    (covid_updated['# covid deaths']> 12)]\n",
    "filtered.loc[:, ['case_fatality_rate', '# covid deaths per 100k', 'population', '# covid deaths']\n",
    "            ].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the distribution has a long tail since the standard deviation is so large compared to the mean in both cases. \n",
    "\n",
    "Since this is the case I will use the median instead of the mean since it is more robust to outliers. \n",
    "\n",
    "2) Looking at the median, the data pulled from counties with around 15 deaths does significantly vary from the overall data, and there are ~200 counties represented, so I am comfortable drawing conclusions from that smaller dataset.\n",
    "\n",
    "3) Find expected cases and population. \n",
    "\n",
    "**Expected population is ~34k** (found from the median population of the filtered data set)\n",
    "\n",
    "**Expected case number is 625** (found by 15/median fatality rate of the filtered data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 3.6: Q4 (1 of 6 pts)</b>\n",
    "    \n",
    "What further questions do you wish to answer about COVID, including ones that may not be possible to answer from this data alone (e.g., Is there a correlation between the average age of people in a county and the # of COVID deaths)? Write at least 3 of your questions.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a correlation between county size and a larger standard deviation an these statistics? i.e are the small counties a source of variability in our data due to small numbers?\n",
    "\n",
    "- Is there a correlation between county wealth and outcomes?\n",
    "\n",
    "- Is there a correlation between nearby hospitals/medical facilities and outcomes for the counties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4. MORE DATA (25 pts)\n",
    "In order to better understand how COVID (and the testing thereof) has impacted our world, we could look at how it relates to demographics, income, education, health, and political voting. For this exercise, we will make use of `election2016_by_county.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.1 [4 pts]: Load more data</b>\n",
    "\n",
    "Complete the `merge_data()` function, which should:\n",
    "1. First, load `election2016_by_county.csv` as a new DataFrame.\n",
    "2. Then, using the state and county names (case-sensitive) in both DataFrames, merge this new DataFrame with your existing `covid_updated`.\n",
    "3. Return the merged DataFrame\n",
    "\n",
    "The returned `merged` DataFrame should contain all 7 columns from `covid_updated`:\n",
    "- county\n",
    "- state\n",
    "- \\# total covid cases\n",
    "- \\# covid cases per 100k\n",
    "- \\# covid deaths\n",
    "- population\n",
    "- case_fatality_rate\n",
    "\n",
    "along with these 14 columns from `election2016_by_county.csv`:\n",
    "- hispanic\n",
    "- minority\n",
    "- female\n",
    "- unemployed\n",
    "- income\n",
    "- nodegree\n",
    "- bachelor\n",
    "- inactivity\n",
    "- obesity\n",
    "- density\n",
    "- cancer\n",
    "- votergap\n",
    "- trump\n",
    "- clinton\n",
    "\n",
    "**NOTES:**\n",
    "- We are dropping two columns from `election2016_by_county.csv`:\n",
    "    - fipscode\n",
    "    - population\n",
    "- Do not attempt to manually fix any of the state or county names. That is, **our merging should require the state and county names to be identical (case-sensitive) between the two DataFrames.** If there is a discrepancy between the two, do not worry about adjusting these names to find a perfect match.\n",
    "\n",
    "**HINT:** there are many ways to solve this, but you may find the [pandas.merge()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) function can be really helpful\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def merge_data(covid_updated, filepath):\n",
    "    \n",
    "    filepath = 'election2016_by_county.csv'\n",
    "    csv = pd.read_csv(filepath, usecols = ['state', 'county', 'hispanic', 'minority',\n",
    "           'female', 'unemployed', 'income', 'nodegree', 'bachelor', 'inactivity',\n",
    "           'obesity', 'density', 'cancer', 'votergap', 'trump', 'clinton'])\n",
    "    \n",
    "    return covid_updated.merge(csv, on = ['state', 'county'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "merged = merge_data(covid_updated, 'election2016_by_county.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As mentioned above, the merging requires exact matching between the two DataFrames' `state` and `county` columns. Thus, some mismatches will occur, yielding our `merged` DataFrame to have fewer rows than `covid_updated` and `election2016_by_county.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.2 [5 pts]: Data Construction / Understanding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.2: Q1 (1 of 5 pts)</b>\n",
    "    \n",
    "Compared to `covid_updated`, how many rows were lost during this merging process to create `merged`? Running the cell below should print to the screen your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(\"{} rows were lost during merge.\".format(covid_updated.shape[0]-merged.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.2: Q2 (2 of 5 pts)</b>  \n",
    "\n",
    "List the county and state of *at least 3* such rows that exist in `covid_updated` but didn't make it into `merged`. Running the cell below should print to the screen your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "covid_updated[~covid_updated['county'].isin(merged['county'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.2: Q3 (2 of 5 pts)</b>  \n",
    "? If we needed to be highly thorough and needed comprehensive data coverage, do you have any suggestions on how we could quickly, soundly fix most or all of them? (Write 2-3 sentences.)\n",
    "    \n",
    "<b>NOTE: Please do not actually fix these mismatches; for this Exercise, it's okay that the `merged` DataFrame is smaller than `covid_updated`</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "It looks like most of the counties that were not included had weird punctuation like dashes or were formatted as 'Williamsburg, City of'.\n",
    "\n",
    "We could check if the standard format in the .csv is 'City of Williamsburg' and if so use regex searching to find these cases and standardize their format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This past example demonstrates how easy it is for data to become messy. It also shows the importance of paying close attention to your data in order to understand what you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Our `case_fatality_rate` column can be viewed as an approximation of how effective and thorough *COVID testing* is for a given county.\n",
    "\n",
    "Our `# covid deaths` column can be viewed as an extreme indication of how severe *COVID* has impacted a given county.\n",
    "\n",
    "Our `# covid cases per 100k` column be viewed as middle-ground between the two aforementioned features. That is, it measures the impact of the disease and is influenced by the thoroughness of COVID testing.\n",
    "\n",
    "Using these three informative features, we can inspect how impacted each county is, while correlating this with other features of each county, such as income-level, health metrics, demographics, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.3 [2 pts]: Cleaning the data</b>\n",
    "\n",
    "Before we do any further analysis, we first notice that some counties haven't encountered a single COVID death (usually ones with very small populations), thus providing us with little information. Write code in the cell below to update the `merged` DataFrame so that all rows with 0 deaths are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "merged = merged[merged['# covid deaths']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Running `.describe()` allows us to quickly see summary statistics of our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the information reported from `.describe()`, we can imagine dividing our DataFrame into 4 separate bins, based on the distribution for any given feature. Specifically, based on a particular feature:\n",
    "- the $1^{st}$ bin will be the data that has values between the **min** and **25%**\n",
    "- the $2^{nd}$ bin will be the data that has values between **25%** and **50%**\n",
    "- the $3^{rd}$ bin will be the data that has values between **50%** and **75%**\n",
    "- the $4^{th}$ bin will be the data that has values between **75%** and **max**\n",
    "\n",
    "<div class='exercise'><b>Exercise 4.4 [3 pts]: Partitioning our data</b>\n",
    "    \n",
    "Complete the `partition_df()` function, which takes as input:\n",
    "- DataFrame to work with\n",
    "- feature (e.g., obesity) to filter by\n",
    "- minimum value\n",
    "- maximum value\n",
    "\n",
    "and outputs:\n",
    "- a subset of the DataFrame that has values between the passed-in minimum and maximum values (inclusively) for the passed-in feature.\n",
    "\n",
    "For example, if we called `partition_df(merged, 'obesity', 30, 45)`, it should return a subset of the `merged` DataFrame that has obesity values between 30 and 45 (and including the boundary values of 30 and 45).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def partition_df(df, column_name, min, max):\n",
    "    return df[(df[column_name] >= min) & \n",
    "              (df[column_name] <= max)].loc[:,['# covid cases per 100k',\n",
    "                                            'case_fatality_rate',\n",
    "                                            '# covid deaths per 100k']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.5: [4 pts] Exploratory Data Analysis</b>\n",
    "    \n",
    "Identify a few features that you're interested in, and inspect if there's any correlation with the COVID data. Specifically, simply run your `partition_df()` function below, many times, each with a different subset of the data -- select a range of values and a particular feature. For example, if I'm interested in __cancer__, I could look at the 4 quartiles (per `.describe()`) and use those ranges of values as I repeatedly execute `partition_df()`. For this exercise, after running the function several times, **write 3-5 sentences about any patterns or correlations you noticed or didn't notice but expected to find.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "var = merged['income'].describe()\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at bottom vs top quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df(merged, 'income', var.loc['min'], var.loc['25%']\n",
    "            ).describe().loc[['count','mean', '50%'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "partition_df(merged, 'income', var.loc['75%'], var.loc['max']\n",
    "            ).describe().loc[['count','mean', '50%'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For income levels, the fatality rate is about the same, but the deaths per 100k is 2x more for low income areas. \n",
    "\n",
    "So this implies that the testing regimin was about the same regardless of income bracket, but poorer counties were hit harder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obesity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = merged['obesity'].describe()\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df(merged, 'obesity', var.loc['min'], var.loc['25%']\n",
    "            ).describe().loc[['count','mean', '50%'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df(merged, 'obesity', var.loc['75%'], var.loc['max']\n",
    "            ).describe().loc[['count','mean', '50%'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same trends are true of areas with higher obesity, although the difference between the two quartiles is less pronounced than with income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "`.describe()` provides these nice summary statistics over any portion of data that we give it. Instead of iteratively inspecting several subsets of the data, let's actually split our DataFrame into new categories; instead of representing all features by floating point numbers, let's create new _categorical_ names for feature(s) based on their numbers. The code below does just this. It creates a new column, `income group` that has 4 possible values, each one corresponding to a quartile of the original `income` values. \n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "bins = [0, 38000, 45000, 52000, 200000]\n",
    "names = ['income-group-1', 'income-group-2', 'income-group-3', 'income-group-4']\n",
    "d = dict(enumerate(names, 1))\n",
    "merged['income group'] = np.vectorize(d.get)(np.digitize(merged['income'], bins))\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.6 [5 pts]: Aggregate data</b>\n",
    "    \n",
    "    \n",
    "Write code in the cell below to group (and display) the data according to the 4 income groups. Also, while we will still keep the same columns (i.e, features), the values of each should now represent the __average__ value of all rows that were subsumed in the making of the aggregate income-group. Your resulting DataFrame should have just 4 rows (income-group-1, income-group-2, income-group-3, income-group-4). See example in the cell below.\n",
    "\n",
    "\n",
    "Since every feature (except for `# total cases`, `# covid deaths`, and `population`) was already an average value corresponding to a particular __county__, when we aggregate our data by income groups, we are effectively taking an average of an average. Many counties are being aggregated for each income-group row. This approach isn't as accurate as possible; it would be more accurate if we re-adjusted every value so that it was truly an average that was based on the total __population__ of all counties that are subsumed within a given income-group row. That's okay, though. An average of averages will suffice for the purpose of this exercise. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# EXAMPLE: If our `merged` DataFrame were\n",
    "# COUNTY    INCOME GROUP    BACHELOR ... (other columns, too)\n",
    "#   A            2             50\n",
    "#   B            1             20\n",
    "#   C            1             30\n",
    "#   D            2             70\n",
    "#   E            3             95\n",
    "\n",
    "# it should become\n",
    "# INCOME GROUP    BACHELOR ... (other columns, too)\n",
    "#   1                25\n",
    "#   2                60\n",
    "#   3                95\n",
    "\n",
    "merged.groupby(by='income group').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.7 [2 pts]: Conclusions</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.7: Q1 (1 of 2 pts)</b>\n",
    "What are your conclusions/finding from this alternative view of the data? (2-4 sentences).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Being in the lowest income group has much worse outcomes. Between the other three groups, the highest income group does have better outcomes, but the gap is largest between the bottom and the 2nd lowest.\n",
    "\n",
    "- All of the income brackets had about the same case fatality rate\n",
    "\n",
    "- some of the other variables, such as 'density', and 'bachelor' correlate well to income, while others such as 'female', 'inactivity', and 'cancer' do not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b>Exercise 4.7: Q2 (1 of 2 pts)</b>\n",
    "What are some weaknesses from this view of the data? (2-4 sentences).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the mean instead of the median seems like a weakness to me given that the data is skewed and with a large standard deviation.\n",
    "\n",
    "- We are using fairly large groups. Since there is such a big gap between the bottom quartile and the third quartile, I wonder where the 'tipping point' of income is. \n",
    "\n",
    "- It is hard to tell which variables have the strongest effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Moving Forward\n",
    "\n",
    "In this homework assignment, we've focused on gathering, parsing, and exploring data. However, what if we wanted to *predict* some behavior of the data. For example, imagine one is curious how a particular county will respond to COVID. Or, imagine we looked at counties' COVID data on a weekly basis, one could be interested in predicting the upcoming week's behavior.\n",
    "\n",
    "Alternatively, one could be interested in *inference*, whereby we are more concerned with trying to understand __why__ and __how__ a system behaves the way it does. We might wish to understand which factors most correlate and cause a certain event to happen. This could give us insights into where certain inequalities persist.\n",
    "\n",
    "For both *prediction* and *inference*, our computational method of solving such a task is referred to as a model. For the remainder of CS109, we will spend significant focus on various models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Reflection\n",
    "\n",
    "As a reminder, this is just **one** of the homework assignments in this course, the point of which is to assess your learning and to provide both you and us with an indication as to how aligned your knowledge and skills are with our learning objectives. To this end, we encourage you to reflect on your progress, strengths, and weaknesses and to make changes, if necessary, to accomplish your goals. Likewise, please reach out to the TFs and teaching staff if you need help. We want everyone to feel comfortable in being honest about these elements, with both herself/himself and us. For these purposes, we will ask you several times throughout the semester to complete an anonymous poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
