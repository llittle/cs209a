{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 4: Predicting College Admissions\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- **THIS IS AN INDIVIDUAL ASSIGNMENT**. \n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- This assignment **must be done individually**.\n",
    "\n",
    "- Please restart the kernel and run the entire notebook again before you submit.\n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. Exceptions should be made for code with a long execution time, of course.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \n",
    "```\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "- Your plots should include clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is not a descriptive title; \"95 % confidence interval of coefficients of polynomial degree 5\" is).\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview and Data Description\n",
    "\n",
    "### Predicting admissions into elite universities\n",
    "\n",
    "In this problem set we will model the chances of high school students being accepted into two different elite undergraduate colleges (one is elite at least :) ): Harvard and Yale.  The data are provided in the file `data/college_admissions.csv` and were scraped from [collegedata.com](https://www.collegedata.com/) (where applicants volunteer to share their information).  Each observation corresponds to an applicant to one of the two different colleges (note: the same applicant may show up in two rows: once for each college).  The main response is the `admitted` variable (1 = admitted, 0 = denied), and there are are several predictors to consider:\n",
    "\n",
    "- **id**: a unique identifier for the applicant \n",
    "- **test**: a standardized measurement of the applicants highest ACT or SAT combined score (2400 is the maximum). \n",
    "- **ap**: the number of AP tests taken\n",
    "- **avg_ap**: the average score on the AP tests taken (0 if no tests were taken)\n",
    "- **sat_subjects**: the number of SAT subject tests taken\n",
    "- **gpa**: the unweighted GPA of applicant (max of 4.0)\n",
    "- **female**:  a binary indicator for gender: 1 = female, 0 = otherwise \n",
    "- **minority**: a binary indicator for under-represented minority: 1 = minority, 0 = otherwise \n",
    "- **international**: a binary indicator for international status: 1 = international, 0 = US\n",
    "- **sports**: a binary indicator for HS All-American: 1 = all-American athlete, 0 = otherwise\n",
    "- **school**: a categorical variable for school applied to: \"Harvard\" or \"Yale\"\n",
    "- **early_app**: a binary indicator for application type: 1 = early action, 0 = regular\n",
    "- **alumni**:  a binary indicator for parents' alumni status of school: 1 = a parent is an alumnus, 0 = otherwise\n",
    "- **program**: the program applied to by the student with many choices (we will not use this as a predictor)\n",
    "- **add_info**: additional (optional) info provided by applicant (we will not use this as a predictor)\n",
    "\n",
    "The main set of 12 predictors is (note: you may need to modify this list when fitting different models, and your will be replacing the `school` variable with a binary `harvard` variable early in the questions below):\n",
    "\n",
    "```python\n",
    "[\n",
    "    'test','ap','avg_ap','sat_subjects','gpa','female',\n",
    "    'minority','international','sports','school','early_app','alumni'\n",
    "]\n",
    "```\n",
    "\n",
    "Please use this dataset to answer the following questions below.\n",
    "\n",
    "**Important notes:**\n",
    "\n",
    "- **Unless stated otherwise, all logistic regression models should be unregularized (use `penalty=\"none\"`) and include the intercept (which is the default in `sklearn`).**\n",
    "\n",
    "\n",
    "- **When printing your output (e.g. coefficients, accuracy scores, etc.), DO NOT just print numbers without context. Please be certain provide clarifying labels for all printed numbers and limit the number of digits showing after decimals to a reasonable length (e.g. 4 decimal points for coefficients and accuracy scores).**\n",
    "\n",
    "\n",
    "- **Also be sure to practice good data science principles: always use train to do analysis and never touch the test set until the very end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class='exercise'><b> Question 1 [16 pts]: Data Exploration using train and basic models </b></div>\n",
    "\n",
    "The first step is to split the observations into an approximate 80-20 train-test split.  Below is some code to do this for you (we want to make sure everyone has the same splits). It also prints the dataset's shape before splitting and after splitting. \n",
    "\n",
    "**IMPORTANT:** While a valid argument could be made to scale our predictors here, please **DO NOT** do so **UNTIL** it is requested of you in **question 4.1**.\n",
    "\n",
    "**1.1** What proportion of observations were admitted overall?  What would be the classification accuracy for a baseline \"naive\" model where we classified ALL applicants as either admitted or not admitted using just this overall proportion to make our decision (i.e. we apply the same outcome to all applicants based on this proportion)?\n",
    "\n",
    "\n",
    "**1.2** Create a binary ('dummy') variable named `harvard` that takes on the value 1 if `school == \"Harvard\"` and 0 otherwise. Now, explore the marginal association of each of our 12 predictors with whether or not an applicant is admitted into the college they applied (`admitted`).  Create a separate **visual** for each predictor to investigage their relationship with college admissions.  **Suggestion:** place these 12 visuals in a *matrix* of subplots with 3 columns and 4 rows.\n",
    "\n",
    "**Note:** We will be using our dummified `harvard` predictor instead of `school` throughout the remainder of this problem set.\n",
    "\n",
    "**1.3** Based on the visuals above, which predictor seems to have the most potential for predicting `admitted`? Why do you think this it the best potential single predictor?\n",
    "\n",
    "\n",
    "**1.4** Fit a logistic regression to predict `admitted` from `harvard` (call it `logit1_4`).  Interpret the coefficient estimates: which college is estimated to be easier to get into?  What are the estimated chances of getting into each school?\n",
    "\n",
    "\n",
    "**1.5** Create a contingency table between `admitted` and `harvard`.  Use this table to calculate and confirm the coefficient estimates in the `logit1_4` model (both the intercept and slope).\n",
    "\n",
    "\n",
    "**1.6** Compare the estimated probabilities of being admitted into the schools to the overall acceptance rate (as seen [here](https://www.ivycoach.com/2023-ivy-league-admissions-statistics/)).  Why may what you've observed in this comparison be the case?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "## DO NOT MODIFY THIS CODE ##\n",
    "#############################\n",
    "\n",
    "college = pd.read_csv('data/college_admissions.csv')\n",
    "np.random.seed(121)\n",
    "\n",
    "college_train, college_test, = train_test_split(\n",
    "    college, test_size=0.2,  random_state = 121, shuffle=True, stratify = college['school']\n",
    ")\n",
    "\n",
    "print(college.shape)\n",
    "print(college_train.shape, college_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.1** What proportion of observations were admitted overall?  What would be the classification accuracy for a baseline \"naive\" model where we classified ALL applicants as either admitted or not admitted using just this overall proportion to make our decision (i.e. we apply the same outcome to all applicants based on this proportion)?\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.2** Create a binary ('dummy') variable named `harvard` that takes on the value 1 if `school == \"Harvard\"` and 0 otherwise. Now, explore the marginal association of each of our 12 predictors with whether or not an applicant is admitted into the college they applied (`admitted`).  Create a separate **visual** for each predictor to investigage their relationship with college admissions.  **Suggestion:** place these 12 visuals in a *matrix* of subplots with 3 columns and 4 rows.\n",
    " \n",
    " **Note:** We will be using our dummified `harvard` predictor instead of `school` throughout the remainder of this problem set.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.3** Based on the visuals above, which predictor seems to have the most potential for predicting `admitted`? Why do you think this it the best potential single predictor?\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.4** Fit a logistic regression to predict `admitted` from `harvard` (call it `logit1_4`).  Interpret the coefficient estimates: which college is estimated to be easier to get into?  What are the estimated chances of getting into each school?\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.5** Create a contingency table between `admitted` and `harvard`.  Use this table to calculate and confirm the coefficient estimates in the `logit1_4` model (both the intercept and slope).\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.6",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**1.6** Compare the estimated probabilities of being admitted into the schools to the overall acceptance rate (as seen [here](https://www.ivycoach.com/2023-ivy-league-admissions-statistics/)).  Why may what you've observed in this comparison be the case?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class='exercise'><b> Question 2 [18 pts]: Interpretable Modeling </b></div>\n",
    "\n",
    "**2.1** Fit a logistic regression model to predict `admitted` from `test` alone (call it `logit2_1`).  Print out the coefficient estimates (both intercept and slope) along with the classification accuracies for this model (on both train and test data). \n",
    "\n",
    "**2.2** What are the estimated chances of an applicant being admitted with an *average* `test` score of 2200?  What about if they had a perfect test score of 2400?  What test score would be needed to have a 50-50 chance of being admitted?\n",
    "\n",
    "**2.3**  Fit a logistic regression model to predict `admitted` from `test` and `avg_ap` (call it `logit2_3`).  Print out the coefficient estimates (both intercept and slope) along with the classification accuracies for this model (on both train and test data). \n",
    "\n",
    "**2.4** Interpret the coefficient estimates in `logit2_3` (not the intercept) and compare the coefficient estimate for `test` to the one from `logit2_1`.  Why has this estimate changed?\n",
    "\n",
    "**Hint:** You may want to inspect the relationship between `test` and `avg_ap` to help get a better sense for what might be happening here.\n",
    "\n",
    "**2.5** Interpret and compare the classification accuracies for the two models (`logit2_1` and `logit2_3`).  Explain why these accuracies are the same or different, and what about the data makes these accuracies so similar of different? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.1** Fit a logistic regression model to predict `admitted` from `test` alone (call it `logit2_1`).  Print out the coefficient estimates (both intercept and slope) along with the classification accuracies for this model (on both train and test data).\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.2** What are the estimated chances of an applicant being admitted with an *average* `test` score of 2200?  What about if they had a perfect test score of 2400?  What test score would be needed to have a 50-50 chance of being admitted?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Interpretation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.3**  Fit a logistic regression model to predict `admitted` from `test` and `avg_ap` (call it `logit2_3`).  Print out the coefficient estimates (both intercept and slope) along with the classification accuracies for this model (on both train and test data).\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.4** Interpret the coefficient estimates in `logit2_3` (not the intercept) and compare the coefficient estimate for `test` to the one from `logit2_1`.  Why has this estimate changed?\n",
    " \n",
    " **Hint:** You may want to inspect the relationship between `test` and `avg_ap` to help get a better sense for what might be happening here.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**2.5** Interpret and compare the classification accuracies for the two models (`logit2_1` and `logit2_3`).  Explain why these accuracies are the same or different, and what about the data makes these accuracies so similar of different?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class='exercise'><b> Question 3 [30 pts]: Harvard and Yale? </b></div>\n",
    "\n",
    "\n",
    "**3.1** Fit a logistic regression model (call it `logit3_1`) to predict `admitted` from 7 predictors: `['harvard', 'test', 'ap', 'avg_ap', 'gpa', 'female', 'minority']`.  Output and interpret the coefficient estimates for the binary predictors in this model.\n",
    "\n",
    "**Hint:** If you have convergence warnings, increasing the maximum number of iterations to 500 (`max_iter=500`) will likely solve the issue.\n",
    "\n",
    "**3.2** Fit a logistic regression model (call it `logit3_2`) to predict `admitted` from 3 predictors: `['harvard', 'test', 'ap']` along with the 2 interaction terms: `harvard` with `test` and `harvard` with `ap`. Name the columns for these interaction terms something sensible.  Print out the coefficient estimates for this model.\n",
    "\n",
    "**3.3** Simplify and write out mathematically the above model from question 3.2 for 2 applicants: (1) someone who is applying to Harvard and for (2) someone who is applying to Yale (keep `test` and `ap` as the unknown $X$s).  The basic framework given to you below may be helpful:\n",
    "\n",
    "$$ \\ln \\left( \\frac{P(Y=1)}{1-P(Y=1)} \\right) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p $$\n",
    "\n",
    "**Note:** All of your mathematical statements should be written out in your markdown cells [using LaTeX](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd). Do not insert images of handwritten math!\n",
    "\n",
    "**3.4** Determine two classification boundaries mathematically for the model in the previous part (using the estimated coefficients): What range of values of `test` as a function of `ap` would an applicant be predicted to more likely than not be admitted into the college they applied? If a student scored a perfect 2400 on `test`, what is the minimum number of AP tests they should take in order to have a better than 50% chance of being admitted into Harvard?\n",
    "\n",
    "**3.5** Create two separate scatterplots (one for Harvard applicants and one for Yale applicants) with the predictor `test` on the y-axis and `ap` on the x-axis where `admitted` is color-coded and the marker denotes train vs. test data.  Then add the appropriate classification boundary from the previous part.  Compare these two plots (both the location of the boundaries and where the points lie around these boundaries).\n",
    "\n",
    "**Note:** As always, please be certain (a) your plot is titled, (b) everything is clearly labeled, and (c) the plot itself is formatted in a manner that makes it easy to read and interpret.\n",
    "\n",
    "**3.6** Fit a logistic regression model (call it `logit3_6`) to predict `admitted` from 4 predictors: `['harvard', 'test', 'female', 'minority']` along with 2 interaction terms: `harvard` with `female` and `harvard` with `minority`.  Print out the coefficient estimates for this model.\n",
    "\n",
    "**3.7** Interpret the coefficients associated with `female` and `minority` (the two main effects AND the two interaction terms).\n",
    "\n",
    "**3.8** Based on this sample, how does it appear that Harvard and Yale compare in admitting these groups?  Why would it be wrong to take this interpretation as truth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.1** Fit a logistic regression model (call it `logit3_1`) to predict `admitted` from 7 predictors: `['harvard', 'test', 'ap', 'avg_ap', 'gpa', 'female', 'minority']`.  Output and interpret the coefficient estimates for the binary predictors in this model.\n",
    " \n",
    " **Hint:** If you have convergence warnings, increasing the maximum number of iterations to 500 (`max_iter=500`) will likely solve the issue.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.2** Fit a logistic regression model (call it `logit3_2`) to predict `admitted` from 3 predictors: `['harvard', 'test', 'ap']` along with the 2 interaction terms: `harvard` with `test` and `harvard` with `ap`. Name the columns for these interaction terms something sensible.  Print out the coefficient estimates for this model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.3** Simplify and write out mathematically the above model from question 3.2 for 2 applicants: (1) someone who is applying to Harvard and for (2) someone who is applying to Yale (keep `test` and `ap` as the unknown $X$s).  The basic framework given to you below may be helpful:\n",
    " \n",
    " $$ \\ln \\left( \\frac{P(Y=1)}{1-P(Y=1)} \\right) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p $$\n",
    " \n",
    " **Note:** All of your mathematical statements should be written out in your markdown cells [using LaTeX](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd). Do not insert images of handwritten math!\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Note: mathematical statements should be written using LaTeX.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.4** Determine two classification boundaries mathematically for the model in the previous part (using the estimated coefficients): What range of values of `test` as a function of `ap` would an applicant be predicted to more likely than not be admitted into the college they applied? If a student scored a perfect 2400 on `test`, what is the minimum number of AP tests they should take in order to have a better than 50% chance of being admitted into Harvard?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Note: mathematical statements should be written using LaTeX.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.5** Create two separate scatterplots (one for Harvard applicants and one for Yale applicants) with the predictor `test` on the y-axis and `ap` on the x-axis where `admitted` is color-coded and the marker denotes train vs. test data.  Then add the appropriate classification boundary from the previous part.  Compare these two plots (both the location of the boundaries and where the points lie around these boundaries).\n",
    " \n",
    " **Note:** As always, please be certain (a) your plot is titled, (b) everything is clearly labeled, and (c) the plot itself is formatted in a manner that makes it easy to read and interpret.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.6",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.6** Fit a logistic regression model (call it `logit3_6`) to predict `admitted` from 4 predictors: `['harvard', 'test', 'female', 'minority']` along with 2 interaction terms: `harvard` with `female` and `harvard` with `minority`.  Print out the coefficient estimates for this model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.7",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.7** Interpret the coefficients associated with `female` and `minority` (the two main effects AND the two interaction terms).\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.8",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**3.8** Based on this sample, how does it appear that Harvard and Yale compare in admitting these groups?  Why would it be wrong to take this interpretation as truth?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class='exercise'><b> Question 4 [24 pts]: Building Predictive Models for admitted </b></div>\n",
    "\n",
    "**4.1** You were instructed to NOT scale predictors in the prior sections above. The primary reason for this was to focus instead on the interpretability of our logistic regression coefficients. However, as we're sure you noticed, the numeric scale among our different predictors varies greatly (i.e. `test` values are in the 1,000's while others are much, much smaller). In practice, we might want to put our predictors all on a similar scale, particularly for regression and/or distance-based algorithms such as $k$-NN classification. (1) Please explain why scaling under these circumstances might be important. Then, (2) actually apply standardized scaling to all of the **non-binary** predictors in our original set of 12 predictors (for both the training and test sets).\n",
    "\n",
    "**Note:** These scaled predictors should be used instead of the original unscaled versions of the predictors for the remainder of this problem set.\n",
    "\n",
    "**4.2** Fit a well-tuned $k$-NN classification model with main effects of all 12 predictors in it (call it `knn_model`).  Use `ks = [1,3,5,9,15,21,51,71,101,151,201]` and 3-fold cross-validation. Plot, on a single set of axes, your resulting cross-validation mean training and mean validation scores at each value $k$. Then, report your chosen $k$ and the classification accuracy on train and test for your final fitted model.\n",
    "\n",
    "**4.3** Fit the full logistic regression model with main effects of all 12 predictors in it (call it `logit_full`). Print out the coefficient estimates and report the classification accuracy on train and test for this model.\n",
    "\n",
    "**4.4** Fit a well-tuned Lasso-like logistic regression model from all 12 predictors in it (call it `logit_lasso`). Use `Cs = [1e-4,1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4]` and 3-fold cross-validation.  Print out the coefficient estimates and report the classification accuracy on train and test for this model.\n",
    "\n",
    "**4.5** Which predictors were deemed important in `logit_lasso`?  Which were deemed unimportant? \n",
    "\n",
    "**4.6** Fit a well-tuned Lasso-like logistic regression model with all important predictors from `logit_lasso` and all the 2-way interactions between them (call it `logit_lasso_interact`).  Again use `Cs = [1e-4,1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4]` and 3-fold cross-validation. Report the classification accuracy on train and test for this model.\n",
    "\n",
    "**4.7** How many of the predictors in our `logit_lasso_interact` model were deemed important and unimportant? (Feel free to just report on the number of them found to be important and unimportant. There is no need to list them all here.)\n",
    "\n",
    "**Hint:** If you have convergence warnings, increasing the maximum number of iterations to 500 (`max_iter=500`) will likely solve the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.1** You were instructed to NOT scale predictors in the prior sections above. The primary reason for this was to focus instead on the interpretability of our logistic regression coefficients. However, as we're sure you noticed, the numeric scale among our different predictors varies greatly (i.e. `test` values are in the 1,000's while others are much, much smaller). In practice, we might want to put our predictors all on a similar scale, particularly for regression and/or distance-based algorithms such as $k$-NN classification. (1) Please explain why scaling under these circumstances might be important. Then, (2) actually apply standardized scaling to all of the **non-binary** predictors in our original set of 12 predictors (for both the training and test sets).\n",
    " \n",
    " **Note:** These scaled predictors should be used instead of the original unscaled versions of the predictors for the remainder of this problem set.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.2** Fit a well-tuned $k$-NN classification model with main effects of all 12 predictors in it (call it `knn_model`).  Use `ks = [1,3,5,9,15,21,51,71,101,151,201]` and 3-fold cross-validation. Plot, on a single set of axes, your resulting cross-validation mean training and mean validation scores at each value $k$. Then, report your chosen $k$ and the classification accuracy on train and test for your final fitted model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(121) # Do not delete or modify this line of code\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.3** Fit the full logistic regression model with main effects of all 12 predictors in it (call it `logit_full`). Print out the coefficient estimates and report the classification accuracy on train and test for this model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.4** Fit a well-tuned Lasso-like logistic regression model from all 12 predictors in it (call it `logit_lasso`). Use `Cs = [1e-4,1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4]` and 3-fold cross-validation.  Print out the coefficient estimates and report the classification accuracy on train and test for this model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.5** Which predictors were deemed important in `logit_lasso`?  Which were deemed unimportant?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.6",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.6** Fit a well-tuned Lasso-like logistic regression model with all important predictors from `logit_lasso` and all the 2-way interactions between them (call it `logit_lasso_interact`).  Again use `Cs = [1e-4,1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4]` and 3-fold cross-validation. Report the classification accuracy on train and test for this model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.7",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.7** How many of the predictors in our `logit_lasso_interact` model were deemed important and unimportant? (Feel free to just report on the number of them found to be important and unimportant. There is no need to list them all here.)\n",
    " \n",
    " **Hint:** If you have convergence warnings, increasing the maximum number of iterations to 500 (`max_iter=500`) will likely solve the issue.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class='exercise'><b> Question 5 [12 pts]: Evaluating Results </b></div>\n",
    "\n",
    "\n",
    "**5.1** Which of the 4 models in problem 4 perform the best based on classification accuracy?  Which performs the worst? Based on these accuracies, how do these models perform compared to your baseline \"naive\" model back in question 1.1?\n",
    "\n",
    "**5.2** Draw the four ROC curves on the same set of axes using the test data.  How do these ROC curves compare?  Do the ROC curves support that the best model identified in question 5.1 is better than the worst model identified in 5.1?  How do you know?\n",
    "\n",
    "**5.3** Calculate and report AUC for all 4 models.  Do the rankings of these 4 models based on AUC match those for classification accuracy?  Why do you think this is the case?\n",
    "\n",
    "**5.4** If you were to use one of these 4 models to present as a prediction model for the website [collegedata.com](https://www.collegedata.com/), which would you use?  What may be the biggest issue if this was a publicly available tool for college applicants to use to determine their chances of getting into Harvard and/or Yale?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.1** Which of the 4 models in problem 4 perform the best based on classification accuracy?  Which performs the worst? Based on these accuracies, how do these models perform compared to your baseline \"naive\" model back in question 1.1?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.2** Draw the four ROC curves on the same set of axes using the test data.  How do these ROC curves compare?  Do the ROC curves support that the best model identified in question 5.1 is better than the worst model identified in 5.1?  How do you know?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.3** Calculate and report AUC for all 4 models.  Do the rankings of these 4 models based on AUC match those for classification accuracy?  Why do you think this is the case?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**5.4** If you were to use one of these 4 models to present as a prediction model for the website [collegedata.com](https://www.collegedata.com/), which would you use?  What may be the biggest issue if this was a publicly available tool for college applicants to use to determine their chances of getting into Harvard and/or Yale?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true
   },
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
