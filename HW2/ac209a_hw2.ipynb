{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 2: kNN and Linear Regression\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL\n",
    "import os\n",
    "import pathlib\n",
    "working_dir = pathlib.Path().absolute()\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ac03bc-f0ec-4c6b-a41a-9c8eeaa80770",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "-5WJkGo16514"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- This homework can be submitted in pairs, and it is encouraged for you to do so. Especially during covid and distancing, this can be a way to work with other students and learn alongside one another. As future data scientists, you will often be expected to work with others, and working in pairs can help practice communicating data science concepts.\n",
    "\n",
    "- Please restart the kernel and run the entire notebook again before you submit.\n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. Exceptions should be made for code with a long execution time, of course.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them. .\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \n",
    "```\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ac03bc-f0ec-4c6b-a41a-9c8eeaa80770",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "-5WJkGo16514"
   },
   "source": [
    "<div class=\"theme\"> Overview </div> \n",
    "\n",
    "This assignment is the first where you will go through the process of loading a dataset, splitting it in train and test sets, \n",
    "pre-processing it, and finally using it to run models and evaluating your results. \n",
    "\n",
    "We have two different datasets, one with car data in **Part 1** and another with data from an Indian matrimonial web site in **Part 2**.\n",
    "\n",
    "For part 1, you will explore two simple methods for prediction,  **k-nearest neighbors regression (kNN)**, a *non-parametric* method, and **linear regression**, a *parametric* method. As you move towards Part 2 of the homework, you will work with multiple linear and polynomial regression.\n",
    "\n",
    "<div style=\"color: red; background: black\">Please note that Question 4 and Question 7 are required for 209a students but are <strong>optional for 109a students</strong>. We include them here for your education, and we believe that if you have time to spend with them you will learn from them. But <strong>if you are in 109a, then Q4 and Q7 are completely optional</strong>. To help manage stress if you are not in 209a, we recommend skipping past these first and then coming back to them once you have finished the rest of the homework if you have time.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "90930c76-e0ee-41b6-ae34-3507c55c55ad",
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c0d45bbc-accf-40bf-9819-f21abadc79a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Gj0IyRyyID1e",
    "outputId": "252f49e5-6651-4bd7-e138-ff8f67d1e551"
   },
   "outputs": [],
   "source": [
    "#Importing standard libraries\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# pandas tricks for better display\n",
    "pd.options.display.max_columns = 50  \n",
    "pd.options.display.max_rows = 500     \n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.precision = 3\n",
    "\n",
    "# Part 2 imports \n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d745a3c0-49ec-46d5-939a-4a12a891ecf2",
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "K1A-j6ks652C"
   },
   "outputs": [],
   "source": [
    "# Run this cell for more readable visuals \n",
    "large = 22; med = 16; small = 10\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'axes.linewidth': 2,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams.update(params)\n",
    "#sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7e70ce31-0411-4589-8fca-2c9592b4f4cc",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "XL6pJ_Em652E"
   },
   "source": [
    "<div class=\"theme\"> Part A: k-NN and Linear Regression</div> \n",
    "\n",
    "### Problem Description: Predicting the Selling Price of Cars on CarDekho.com\n",
    "\n",
    "According to its website, **CarDekho.com** is India's leading car search venture. \n",
    "Its website and app carry rich automotive content such as expert reviews, \n",
    "detailed specs and prices, comparisons as well as videos and pictures of all car brands and models available in India. \n",
    "Each car has a **Current selling price**, which is the price for buying the car on this site, and a **MRP**, \n",
    "which is the retail price of the car. These two prices differ depending on factors such as brand, \n",
    "make year, millage, condition, etc.  \n",
    "\n",
    "#### Data set \n",
    "\n",
    "The dataset contains 601 cars and is in file `car_dekho_full.csv`. It contains the following columns:\n",
    "\n",
    "- **Year** - make year (year the car was made), \n",
    "- **Current_Selling_Price** - current price of a car on CarDekho.com (in lakhs),\n",
    "- **MRP** - maximum retail price of a car (in lakhs). \n",
    "- **Kms_Driven** - number of kilometers\n",
    "\n",
    "Note: 1 *lakh*  is 100,000 Rupees in the Indian numbering system. Also, kilometers are used as a measure of distance instead of miles.\n",
    "\n",
    "#### Your Task: \n",
    "Predict the `Current_Selling_Price` from the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f730863d-8973-4500-a833-88ae80ff8d60",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "56zUJ3q4652F"
   },
   "source": [
    "<div class='exercise'><b> Question 1:   Exploratory Data Analysis (EDA) [10 pts]</b>\n",
    "\n",
    "To reach the goal of predicting the `Current_Selling_Price`, start by inspecting the dataset using Exploratory Data Analysis (EDA).\n",
    "\n",
    "Load the dataset, inspect it and answer the following questions: \n",
    "\n",
    "**1.1** Which variables are quantitative, and which are categorical? \n",
    "\n",
    "**1.2** What are the means and standard deviations for `Current_Selling_Price` and `MRP`? \n",
    "\n",
    "**1.3** What is the range of Kilometers that the cars have?\n",
    "\n",
    "**1.4** The goal of this part is to identify the best variable from which to predict our respone variable `Current Selling Price`. Plot a scatter plot between each predictor and reponse variable and examine the relationship between the predictors and `Current_Selling_Price`. Based on the plots, which is the  predictor that visually seems to best predict the `Current_Selling_Price`? \n",
    "    \n",
    "    \n",
    "Note: In general, it is always good to label your axes, title your graphs, and produce visuals which clearly communicate the data. Visuals should often be accompanied by text identifying the key point of the visual and defending any choices you make as a data scientist regarding the visual to best communicate your data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "## Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.1** Which variables are quantitative, and which are categorical?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv('data/car_dekho_full.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Year is a categorical data in that it is not continuous, but it is ordered. \"\n",
    "      \"Selling price, max retail price, and kilometers driven are \"\n",
    "      \"all quantitative variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.2** What are the means and standard deviations for `Current_Selling_Price` and `MRP`?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# name your variables mean_csp, mean_mrp, std_csp, std_mrp\n",
    "# your code here\n",
    "df = cars.describe()\n",
    "mean_csp = df['Current_Selling_Price'].mean()\n",
    "std_csp = df.loc['std', 'Current_Selling_Price']\n",
    "mean_mrp = df.loc['mean', 'MRP']\n",
    "std_mrp = df.loc['std', 'MRP']\n",
    "\n",
    "print(f\"The mean selling price is {mean_csp:.2f} lakhs with a standard deviation of {std_csp:.2f}.\"\n",
    "      f\"The mean maximum retail price is {mean_mrp:.2f} lakhs with a standard deviation of {std_mrp:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.3** What is the range of Kilometers that the cars have?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(f\"The car with the lowest number of Km on it has {df.loc['min','Kms_Driven']} km. \"\n",
    "     f\"The car with the highest number of Km on it has {df.loc['max', 'Kms_Driven']} km.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.4** The goal of this part is to identify the best variable from which to predict our respone variable `Current Selling Price`. Plot a scatter plot between each predictor and reponse variable and examine the relationship between the predictors and `Current_Selling_Price`. Based on the plots, which is the  predictor that visually seems to best predict the `Current_Selling_Price`?\n",
    " \n",
    " \n",
    " Note: In general, it is always good to label your axes, title your graphs, and produce visuals which clearly communicate the data. Visuals should often be accompanied by text identifying the key point of the visual and defending any choices you make as a data scientist regarding the visual to best communicate your data.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "y = cars['Current_Selling_Price']\n",
    "for x in ['Kms_Driven', 'MRP', 'Year']:\n",
    "    plt.figure()\n",
    "    plt.xlabel(x)\n",
    "    plt.title(f\"Relationship between {x} and current selling price\")\n",
    "    plt.ylabel(\"Current Selling Price\")\n",
    "    plt.scatter(cars[x],y)\n",
    "    \n",
    "year_df = cars.groupby(by='Year').mean()\n",
    "x = \"year\"\n",
    "plt.figure()\n",
    "plt.xlabel(x)\n",
    "plt.title(f\"Relationship between {x} and mean current selling price\")\n",
    "plt.ylabel(\"Current Selling Price\")\n",
    "plt.scatter(year_df.index, year_df['Current_Selling_Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Based on the graphs above, it seems that the strongest \n",
    "predictor of current selling price is maximum retail price, \n",
    "although year also seems like a fairly good predictor. Kilometers driven seems to have a slight negative correlation with current selling price, but it is not ver strong. \n",
    "\n",
    "Since year is a discrete variable, it is hard to see all of the data points when plotting year vs current selling price. Therefore I chose to also plot the mean selling price for each year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "975ddc7c-c6ac-4dd1-b74f-58d2c1166e5e",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "J8zCuiT9653A"
   },
   "source": [
    "<div class='exercise'><b> Question 2:   k-Nearest Neighbors [25 pts]</b>\n",
    "\n",
    "We begin our modeling with k-Nearest Neighbors (kNN) regression. You may use `sklearn`'s built-in functions.\n",
    "\n",
    "**2.1** In this part, we will model a kNN regression on the predictor chosen above (1.4) and the response variable `Current_Selling_Price`.\n",
    "\n",
    "    \n",
    "INSTRUCTIONS:\n",
    "- Split the dataset in train and test set with 75% training data and 25% testing data, using the random_state = 109.  \n",
    "- Fit a kNN regression model to the training set for the following 8 different values of $k$:  $k = 1,2,3,5,7,10,50,100$. \n",
    "- Make 8 scatter plots of response vs. predictor for each $k$, arranged in a $4\\times2$ grid.  Each figure should have plots of the prediction from the k-NN regression and the actual data points on the same figure, as well as axis labels, title, and legend. Consider using the subplot functionality, unless you first try this and then decide that you have a clearer, cleaner way of communicating these plots. \n",
    "- Evaluate the $MSE$ for the fitted models on both the training and test sets **for each $k$**.\n",
    "- Plot the training and test $MSE$ values as a function of $k$ on the same figure.  Again, the figure must have axis labels and a legend.\n",
    "- Find the best model based on the test $MSE$ values.\n",
    "- Evaluate and report the $R^2$ of the best model.\n",
    "\n",
    "**2.2** Discuss your results by answering the following questions.  You should answer the questions directly in a markdown cell of your notebook.\n",
    "\n",
    "- How does the value of $k$ affect the fitted model?\n",
    "\n",
    "- If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?  \n",
    "\n",
    "- Do the training and test $MSE$ plots exhibit different trends?  Explain how the value of $k$ influences the training and test $MSE$ values.\n",
    "\n",
    "- Run the same code by changing the random seed during the train-test split. Do you always get the same answer? If not, why?\n",
    "    \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6945faa8-539f-43ba-a531-337ccc393bda",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "iZMcq7c4CKAT"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.1** In this part, we will model a kNN regression on the predictor chosen above (1.4) and the response variable `Current_Selling_Price`.\n",
    " \n",
    " \n",
    " INSTRUCTIONS:\n",
    " - Split the dataset in train and test set with 75% training data and 25% testing data, using the random_state = 109.\n",
    " - Fit a kNN regression model to the training set for the following 8 different values of $k$:  $k = 1,2,3,5,7,10,50,100$.\n",
    " - Make 8 scatter plots of response vs. predictor for each $k$, arranged in a $4\\times2$ grid.  Each figure should have plots of the prediction from the k-NN regression and the actual data points on the same figure, as well as axis labels, title, and legend. Consider using the subplot functionality, unless you first try this and then decide that you have a clearer, cleaner way of communicating these plots.\n",
    " - Evaluate the $MSE$ for the fitted models on both the training and test sets **for each $k$**.\n",
    " - Plot the training and test $MSE$ values as a function of $k$ on the same figure.  Again, the figure must have axis labels and a legend.\n",
    " - Find the best model based on the test $MSE$ values.\n",
    " - Evaluate and report the $R^2$ of the best model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#predictor - MRP\n",
    "#response - Current Selling Price\n",
    "x = cars[['MRP']]\n",
    "y = cars['Current_Selling_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##Splitting the data into train and test sets with 75% training data and 25% testing data. Set random_state=109\n",
    "# your code here\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "        train_size = 0.75, random_state = 109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#FF00FF>NEED TO FIX THE PLOTTING HERE</font>\n",
    "Check that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "## Fit a kNN regression model to the training set for the following 8 different values of  ùëò :  ùëò=1,2,3,5,7,10,50,100 .\n",
    "## and make 8 scatter plots of response vs. predictor for each  ùëò , arranged in a  4√ó2  grid. \n",
    "## Each figure should have plots of the prediction from the k-NN regression and the actual data points on the same figure, as well as axis labels, title, and legend\n",
    "# your code here \n",
    "\n",
    "k_list = [1,2,3,5,7,10,50,100]\n",
    "MSE_train = {}\n",
    "MSE_test = {}\n",
    "\n",
    "plt.scatter(cars['MRP'], cars['Current_Selling_Price'])\n",
    "\n",
    "for k in k_list:\n",
    "    #fit the model\n",
    "    model = KNeighborsRegressor(n_neighbors = k)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    #sort the values so I can plot them nicely\n",
    "    #not sorting them also lead to very bad MSE behavior\n",
    "    #because I was comparing a sorted y_pred with an unsorted\n",
    "    #y_test!!\n",
    "    \n",
    "    x_test = x_test.sort_values(by='MRP')\n",
    "    y_test = y_test.loc[x_test.index]\n",
    "    \n",
    "    #test on testing data\n",
    "    y_pred = model.predict(x_test)\n",
    "    MSE_test[k] = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    #test on training data\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    MSE_train[k] = mean_squared_error(y_train, y_train_pred)\n",
    "    \n",
    "    #plot the fits\n",
    "    plt.plot(x_test,y_pred, '.-', label = f'k = {k}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Now make MSE plots\n",
    "plt.plot(k_list, [*MSE_test.values()],'k.-', label = 'Testing Data')\n",
    "plt.plot(k_list, [*MSE_train.values()],'b.-', label = 'Training Data')\n",
    "\n",
    "plt.xlabel('k',fontsize=20)\n",
    "plt.ylabel('MSE',fontsize = 20)\n",
    "plt.title('$MSE$ values vs k values - KNN regression',fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Find the best model\n",
    "min_index = np.argmin([*MSE_test.values()])\n",
    "best_k = k_list[min_index]\n",
    "best_MSE = min(MSE_test.values())\n",
    "print(f\"The model with the lowest MSE value of {best_MSE:.2f} has a k of {best_k}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##Compute the R-squared for the best model\n",
    "best_model = KNeighborsRegressor(n_neighbors=best_k)\n",
    "best_model.fit(x_train, y_train)\n",
    "best_y_pred = best_model.predict(x_test)\n",
    "best_r = r2_score(y_test, best_y_pred)\n",
    "print(f\"The R^2 score of the best model is {best_r:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.2** Discuss your results by answering the following questions.  You should answer the questions directly in a markdown cell of your notebook.\n",
    " \n",
    " - How does the value of $k$ affect the fitted model?\n",
    " \n",
    " - If $n$ is the number of observations in the training set, what can you say about a k-NN regression model that uses $k = n$?\n",
    " \n",
    " - Do the training and test $MSE$ plots exhibit different trends?  Explain how the value of $k$ influences the training and test $MSE$ values.\n",
    " \n",
    " - Run the same code by changing the random seed during the train-test split. Do you always get the same answer? If not, why?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "- The value of k affects the fitted model by choosing how many nearest neighbors it will look at. If the k is low, the model may overfit to the trianing data. If the k is high, the model can average out real trends.\n",
    "\n",
    "- If the $k = n$, then the model is just taking the average of all the data points, the value of the predictor will not affect the prediction at all.\n",
    "\n",
    "- The MSE vs k plots look different for training and testing data. Lower k values look much better for training data than they do for testing data. This makes sense because the low k is essentially overfitting to the training data, so of course it will perform well with that data. \n",
    "\n",
    "- No. When I change the random seed to 209 and then to 100, I get 'best model k values' of 1 and 5 respectively. Perhaps the fitting function is not a convex function so the graident descent is getting caught it local minima depending on where the random state starts the algorithm in.\n",
    "\n",
    "## <font color = #FF00FF> Why is this? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0df4f7c4-d116-437d-82e9-31e392449549",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "fTVuBYybmZUU"
   },
   "source": [
    "<div class='exercise'><b> Question 3:  Simple Linear Regression [25 pts]</b>\n",
    "\n",
    "**3.1** We will now fit our data using a linear regression model. Choose the same **predictor** and **response** variables used to model kNN regression.\n",
    "\n",
    "- You will use the same 75% training and 25% testing split of the data, using the same random_state = 109. \n",
    "- Run a Linear Regression model.\n",
    "- Report the slope/coefficient and intercept values for the fitted linear model.\n",
    "- Report the $MSE$ for the training and test sets and the $R^2$ from the test set.\n",
    "- Plot the **residuals** $e = y - \\hat{y}$ of the model on the training set as a function of the response variable. Draw a horizontal line denoting the zero residual value on the Y-axis.\n",
    "\n",
    "**Note:** Use the `sklearn` module for linear regression. This module has built-in functions to summarize the results of regression and produce residual plots. Create a `Linear Regression` model, use the `fit` method in the instance for fitting a linear regression model, and use the `predict` method to make predictions. As previously, you may use the `mean_squared_error` function to compute $MSE$.\n",
    "    \n",
    "**3.2** Discuss your results by answering the following questions.  \n",
    "\n",
    "- How does the test $MSE$ score compare with the best test $MSE$ value obtained with k-NN regression? \n",
    "\n",
    "- What does the sign of the slope of the fitted linear model convey about the relationship between the predictor and the response?\n",
    "\n",
    "- Discuss the shape of the residual plot and what it shows for the quality of the model. Be sure to discuss whether or not the assumption of linearity is valid for this data.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.1** We will now fit our data using a linear regression model. Choose the same **predictor** and **response** variables used to model kNN regression.\n",
    " \n",
    " - You will use the same 75% training and 25% testing split of the data, using the same random_state = 109.\n",
    " - Run a Linear Regression model.\n",
    " - Report the slope/coefficient and intercept values for the fitted linear model.\n",
    " - Report the $MSE$ for the training and test sets and the $R^2$ from the test set.\n",
    " - Plot the **residuals** $e = y - \\hat{y}$ of the model on the training set as a function of the response variable. Draw a horizontal line denoting the zero residual value on the Y-axis.\n",
    " \n",
    " **Note:** Use the `sklearn` module for linear regression. This module has built-in functions to summarize the results of regression and produce residual plots. Create a `Linear Regression` model, use the `fit` method in the instance for fitting a linear regression model, and use the `predict` method to make predictions. As previously, you may use the `mean_squared_error` function to compute $MSE$.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Prepare your data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "        train_size = 0.75, random_state = 109)\n",
    "\n",
    "x_test = x_test.sort_values(by='MRP')\n",
    "y_test = y_test.loc[x_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "## Fit a linear model to the train data\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "y_train = model.predict(x_train)\n",
    "\n",
    "#plot the data just to make sure everything looks good\n",
    "plt.plot(x_test,y_pred, 'k')\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.title(\"Liner regression model\")\n",
    "plt.xlabel(\"MRP (lakhs)\")\n",
    "plt.ylabel(\"Current selling price (lakhs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "## Report the slope/coefficient and intercept values for the fitted linear model. \n",
    "print(f\"The slope of the model is {model.coef_[0]:.2f} and the \"\n",
    "      f\"intercept is {model.intercept_:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "## Report the $MSE$ and $R^2$ from the training and test sets.\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(f\"For the test data the MSE value is {MSE:.2f}, and the R2 is {R2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "## Plot the **residuals** \n",
    "residuals = y_test - y_pred\n",
    "plt.hlines(y=0, xmin = min(y_test)-1, xmax = max(y_test)+1)\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.title(\"Residual vs response variable\")\n",
    "plt.xlabel(\"Predicted Current Sales Price (lakhs)\")\n",
    "plt.ylabel(\"Residual (lakhs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.2** Discuss your results by answering the following questions.\n",
    " \n",
    " - How does the test $MSE$ score compare with the best test $MSE$ value obtained with k-NN regression?\n",
    " \n",
    " - What does the sign of the slope of the fitted linear model convey about the relationship between the predictor and the response?\n",
    " \n",
    " - Discuss the shape of the residual plot and what it shows for the quality of the model. Be sure to discuss whether or not the assumption of linearity is valid for this data.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "- The best test MSE I got with k-NN regression was 2.85 (with a random seed of 100). The linear MSE is slightly higher, but not much.\n",
    "- The slope signifies how much the selling price will increase in lakhs for every one increase in lahks of the maximum retail price.\n",
    "- There does not seem to be any non-linear predicted y dependence in the residuals. It is clear that the model is worse for higher predicted sales price values, but the linear model seems valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f75ca718-99c3-4510-bf2e-53fbd9f1eb8d",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "D6bKVOhn653e"
   },
   "source": [
    "<div class='exercise'><b> Question 4 (for 209a students, optional for others):  Linear Regression with Feature engineering [10 pts]</b>\n",
    "\n",
    "**4.1** Creating a new variable from existing data: percentage depreciation\n",
    "\n",
    "Feature engineering involves transforming data into features that better represent the underlying problem to the predictive models. This results in improved model accuracy on unseen data. \n",
    "\n",
    "Our previous regression model relates the Current selling price to the MRP of the car with the equation:\n",
    "\n",
    "$$CSP = \\beta_0 + \\beta_1*MRP$$\n",
    "\n",
    "However, this linear equation does not incorparate other interesting variables such as the ```year of manufacture```, or the ```kms driven```, which may be important factors that affect the overall price of the car. \n",
    "\n",
    "Instead of using multi-linear analysis, we can perform some intelligent feature engineering to identify other simple linear relationships within our data.\n",
    "\n",
    "From practical experience, we know that the percentage drop of a car's price is proportional to the age of the car ([more on car depreciation here](https://www.finder.com/what-is-car-depreciation)). \n",
    "\n",
    "Hence, it makes sense to investigate this variable seperately and try to identify possible relationships with other variables.  \n",
    "\n",
    "Define the percentage depreciation of the Current selling price to the MRP as follows:\n",
    "\n",
    "$$\\textrm{Percentage of the Selling Price}=perc =\\frac{MRP - Selling Price}{MRP}$$\n",
    "    \n",
    "Create a new column in your dataframe for `perc`\n",
    "    \n",
    "    \n",
    "**4.2** Exploratory Data Analysis\n",
    "\n",
    "For this section, we will consider `perc` to be our intermediate response variable. To understand the relationship between `perc` and our predictor variables we will perform EDA.\n",
    "\n",
    "Answer the following questions by plotting graphs.\n",
    "\n",
    "a) It is seen previosuly that there is a relationship between `Year` and `Current Selling Price`. Is the relationship between `Years` and `perc` the same. If not, how has it changed and why do you think so?\n",
    "\n",
    "b) Is the trend between the `MRP` and `perc` the same as that between `MRP` and `Current Selling Price`?\n",
    "\n",
    "c) Does there seem to be a relationship between `Kms_Driven` and `perc` ? \n",
    "\n",
    "d) Which is the best predictor to predict `perc`, if there is one? Is it the same as that of `Current Selling price` or has it changed?\n",
    "\n",
    "**4.3** Perform additional EDA \n",
    "\n",
    "Use other plots and statistics to find the best predictor and/or understand the relationship between the other variables and `perc`. One example is given below. It is a plot of `perc` vs `Year` that is color coded based on the `Kms_Driven`.\n",
    "\n",
    "**4.4** Fitting a Linear Regression model\n",
    "\n",
    "Based on the previous EDA choose appropriate **feature** variable(s) and **response** variable (`perc`).\n",
    "\n",
    "- Again, use the same split train-test sets with training data of 75% and testing data of 25%\n",
    "- Fit a Linear Regression model for each of the predictors.\n",
    "- Predict the model for the train and test data\n",
    "- Plot a graph with the test data with predictor variable on the *x* axis and `perc` on the *y* axis. Also plot the fit curve. Ensure you use the correct labels and show the legend.\n",
    "- Report the $MSE$ score from the training and test sets.\n",
    "- Find the best model i.e. the best predictor based on the $MSE$ of each model.\n",
    "\n",
    "**4.5** Predicting The Current Selling Price using ```perc``` \n",
    "\n",
    "After performing the above analysis, answer briefly as to why are we getting such a dramatic increase in the R2 score.\n",
    "    \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7be4db8-2c8f-437e-b016-659c755a08f1",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KNnTUgmwkWs5"
   },
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.1** Creating a new variable from existing data: percentage depreciation\n",
    " \n",
    " Feature engineering involves transforming data into features that better represent the underlying problem to the predictive models. This results in improved model accuracy on unseen data.\n",
    " \n",
    " Our previous regression model relates the Current selling price to the MRP of the car with the equation:\n",
    " \n",
    " $$CSP = \\beta_0 + \\beta_1*MRP$$\n",
    " \n",
    " However, this linear equation does not incorparate other interesting variables such as the ```year of manufacture```, or the ```kms driven```, which may be important factors that affect the overall price of the car.\n",
    " \n",
    " Instead of using multi-linear analysis, we can perform some intelligent feature engineering to identify other simple linear relationships within our data.\n",
    " \n",
    " From practical experience, we know that the percentage drop of a car's price is proportional to the age of the car ([more on car depreciation here](https://www.finder.com/what-is-car-depreciation)).\n",
    " \n",
    " Hence, it makes sense to investigate this variable seperately and try to identify possible relationships with other variables.\n",
    " \n",
    " Define the percentage depreciation of the Current selling price to the MRP as follows:\n",
    " \n",
    " $$\\textrm{Percentage of the Selling Price}=perc =\\frac{MRP - Selling Price}{MRP}$$\n",
    " \n",
    " Create a new column in your dataframe for `perc`\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "cars['perc'] = (cars['MRP'] - cars['Current_Selling_Price'])/cars['MRP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.2** Exploratory Data Analysis\n",
    " \n",
    " For this section, we will consider `perc` to be our intermediate response variable. To understand the relationship between `perc` and our predictor variables we will perform EDA.\n",
    " \n",
    " Answer the following questions by plotting graphs.\n",
    " \n",
    " a) It is seen previosuly that there is a relationship between `Year` and `Current Selling Price`. Is the relationship between `Years` and `perc` the same. If not, how has it changed and why do you think so?\n",
    " \n",
    " b) Is the trend between the `MRP` and `perc` the same as that between `MRP` and `Current Selling Price`?\n",
    " \n",
    " c) Does there seem to be a relationship between `Kms_Driven` and `perc` ?\n",
    " \n",
    " d) Which is the best predictor to predict `perc`, if there is one? Is it the same as that of `Current Selling price` or has it changed?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def EDA(x, y, x_label = None, y_label = None):\n",
    "    plt.figure()\n",
    "    plt.scatter(cars[x], cars[y])\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label)\n",
    "    else:\n",
    "        plt.xlabel(x)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label)\n",
    "    else:\n",
    "        plt.ylabel(y)\n",
    "    \n",
    "\n",
    "\n",
    "EDA('Year', 'Current_Selling_Price')\n",
    "EDA('Year', 'perc', y_label = 'Percent Derpecation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Current selling price generally increases with the year, wheras precentage deprecation decreases with year. This makes sense, because if the cars started out the same price, if the price deprecates the selling price will be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "EDA('MRP', 'Current_Selling_Price')\n",
    "EDA('MRP', 'perc', y_label = 'Percentage Deprecation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The relationship between MRP and current selling price is NOT the same as the relationship between MRP and precentage deprecation. There does not seem to be a strong correlation between MRP and precentage deprecation, wheras there is a strong relationship between MRP and current selling price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "EDA('Kms_Driven', 'perc', y_label = \"Percentage Deprecation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "There is a correlation between kilometers driven and percentage deprecation. Generally the more kilometers a car has been driven, the higher the deprecation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "It seems that both year and kilometers driven are good indicators of the percentage deprecation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.3",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.3** Perform additional EDA\n",
    " \n",
    " Use other plots and statistics to find the best predictor and/or understand the relationship between the other variables and `perc`. One example is given below. It is a plot of `perc` vs `Year` that is color coded based on the `Kms_Driven`.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "newdf = cars.copy()\n",
    "\n",
    "newdf['bins'] = np.int64(newdf.Kms_Driven/30000)\n",
    "\n",
    "bins = newdf.bins.unique()\n",
    "\n",
    "bins.sort()\n",
    "\n",
    "fg = sns.FacetGrid(data= newdf, hue = 'bins',hue_order = bins,\n",
    "                  height = 6, aspect = 1.61)\n",
    "fg.map(plt.scatter, 'Year','perc')\n",
    "plt.legend(['<30k','30-60k','60-90k','90-120k','120-150k','150-180k','180k+'],loc='lower left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA('Current_Selling_Price', 'perc') # MRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There is a slight negative correlation between current selling price and precentage deprecation. Not as strong as Kms driven or year though. This implies that if the current selling price is very high, it is more likely that the precentage of deprecation is low, which makes sense because if an car that is being sold for a lot of money has already deprecated a lot, it must have started out even more expensive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.sort(cars['Year'].unique())\n",
    "fg = sns.FacetGrid(data= cars, hue = 'Year', height = 6, aspect = 1.61, hue_order = years)\n",
    "fg.map(plt.scatter, 'Kms_Driven','perc')\n",
    "plt.legend(years, loc = 'right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows the same data as the provided example but with the hue and x axes switched. It seems that since kms driven and year correlated, I am not sure how useful using both will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.4",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.4** Fitting a Linear Regression model\n",
    " \n",
    " Based on the previous EDA choose appropriate **feature** variable(s) and **response** variable (`perc`).\n",
    " \n",
    " - Again, use the same split train-test sets with training data of 75% and testing data of 25%\n",
    " - Fit a Linear Regression model for each of the predictors.\n",
    " - Predict the model for the train and test data\n",
    " - Plot a graph with the test data with predictor variable on the *x* axis and `perc` on the *y* axis. Also plot the fit curve. Ensure you use the correct labels and show the legend.\n",
    " - Report the $MSE$ score from the training and test sets.\n",
    " - Find the best model i.e. the best predictor based on the $MSE$ of each model.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# split up the data\n",
    "def lin_model(x, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cars[[x]], cars[y], train_size = 0.75,\n",
    "                                                   random_state = 100)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x_train, y_pred_train, label = \"Train Pred\")\n",
    "    plt.scatter(x_train, y_train, label = \"Train Data\")\n",
    "    plt.plot(x_test, y_pred_test, 'k', label = \"Test Pred\")\n",
    "    plt.scatter(x_test, y_test, label = \"Test Data\")\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    MSE_train = mean_squared_error(y_test, y_pred_test)\n",
    "    MSE_test = mean_squared_error(y_train, y_pred_train)\n",
    "        \n",
    "    print(f\"Using {x} as a predictor, the MSE on the test data \"\n",
    "          f\"is {MSE_test:.2f}, and the MSE on the train data \"\n",
    "          f\"is {MSE_train:.2}.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "kms_perc_model = lin_model('Kms_Driven', 'perc')\n",
    "year_perc_model =lin_model('Year', 'perc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.5",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.5** Predicting The Current Selling Price using ```perc```\n",
    " \n",
    " After performing the above analysis, answer briefly as to why are we getting such a dramatic increase in the R2 score.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "B0 = year_perc_model.intercept_\n",
    "B1 = year_perc_model.coef_\n",
    "\n",
    "#combine the two equations we have to calucuate percent deprecation \n",
    "#to get a new way to predict CSP \n",
    "csp_pred = -(B0+B1*cars['Year'])*cars['MRP']+cars['MRP']\n",
    "\n",
    "#calculate the R^2 term\n",
    "R2 = r2_score(cars['Current_Selling_Price'], csp_pred)\n",
    "\n",
    "print(f\"My new model gives an R^2 of {R2:.2f}, while using only MRP, as in problem 3.1, gives an R^2 of only 0.81\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The new model is a linear regression that also includes an interaction term between year and MRP. \n",
    "We likely could have done this without using the perc equations and just directly fit an equation such as \n",
    "\n",
    "CSP = B0 + B1\\*MRP + B2\\*Year + B3\\*MRP\\*Year\n",
    "\n",
    "but using the perc variable gives a more real-world tie-in between the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da342829-572c-4a6b-bb45-a2d2f3d0468e",
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"theme\"> Part Œí :  Multi-Linear Regression</div> \n",
    "\n",
    "### Problem Description: \n",
    "\n",
    "Analysis of publically available profiles on simplymarry.com to learn more about the biases, income disparity & other interesting trends in India. \n",
    "\n",
    "#### Dataset\n",
    "\n",
    "The dataset was aggregated from the SimplyMarry.com site and given in `Income_prediction.csv'.\n",
    "\n",
    "All the attributes refer to traits and preferences of the person looking for a spouse. \n",
    "\n",
    "- **age** - Age of person looking for a spouse\n",
    "- **gender** - Female:0, Male:1 \n",
    "- **height** - Height in inches\n",
    "- **bmi** - BMI calculated based on height and weight\n",
    "- **eating** - {'Doesn't Matter':0, 'Jain': 1, 'Vegetarian': 2, 'Vegetarian With Eggs': 3, 'Non Vegetarian': 4}\n",
    "- **family_type** - ('Doesn't Matter': 0, 'Others':3, 'Nuclear': 1, 'Joint family both parents': 2, 'Joint family only mother':2, 'Joint family father mother and brothers sisters':2, 'Joint family single parent brothers and or sisters':2, 'Joint family only father': 2)\n",
    "- **status** - If social status matters to the person looking for a spouse: {'Doesn't Matter': 0, 'Middle Class': 1, 'Upper Middle Class': 2, 'High Class': 3, 'Rich / Affluent': 4}\n",
    "- **manglik** - {'No': 0, 'Yes': 1, 'Do Not Know': 2} ([More on this feature](https://en.wikipedia.org/wiki/Mangala_Dosha))\n",
    "- **drinking** - {'Doesn't Matter':0, 'No': 1, 'Occasionally': 2, 'Yes': 3}\n",
    "- **complexion** - {'Very Fair ': 1, 'Fair ': 2, 'Wheatish ':3, 'Wheatish Medium ': 4, 'Dark':5}\n",
    "- **body** - {'Slim': 1, 'Average': 2, 'Heavy': 3, 'Athletic': 4}\n",
    "- **education** - {'High School':0, 'Some college':1,'Undergrad':2, 'Grad':3, 'Doctorate':4}\n",
    "- **city** - ('International': 1, 'Mumbai': 2, 'Delhi':3, 'Kolkata':4,'Bengaluru':5, 'Chennai':6, 'Hyderabad':7, 'Pune':8, 'Ahmedabad':9,'Surat':10, 'Vishakapatnam':11, 'Others':12)\n",
    "- **income** - {Annual income in dollars}\n",
    "\n",
    "*source: Harvard IACS*\n",
    "\n",
    "#### Sensitive attributes in the data\n",
    "\n",
    "It is thought that users are mostly sincere when stating their preferences about their desired partner, and are less likely to hide any deeply held cultural or sociological biases or preferences in order to be perceived as being politically or socially \"correct\". This might take care of the problem with surveys where responses touching on social norms are notorious for self-report bias, referred to as \"social desirability bias.\" However, the possibility of bias persists; it might be possible to imagine somebody selecting that drinking \"doesn't matter\" but they might still have some type of preference, unconscious or conscious. \n",
    "\n",
    "This is a dataset designed to help us think about issues of bias and social issues in datasets. We hope that you will be able to derive insights into the above mentioned sociological biases. The data could potentially provide answers to interesting questions with associated policy ramifications, such as a possible relationship between bias and factors like education, local environment, or age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c919f665-f1a2-46dd-955c-4cc11bc3ec5d",
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 5:   Using Data science to learn more about Indian society [25 pts]</b>\n",
    "\n",
    "First we are going to use simple analytics to learn more about Indian society with the help of this dataset.\n",
    "\n",
    "The idea is to use basic modeling based on averages & sample distributions to uncover suspected biases, such as gender, skin tone & manglik status.\n",
    "\n",
    "Answer the below questions using plots & simple statistics.\n",
    "\n",
    "**5.1** Is there a disparity in income of participants by gender? Consider using a log scale or another technique to communicate clearly.\n",
    "\n",
    "**5.2** Is there a relationship between income and the \"eating\" variable? Is there a relationship between income and skin complexion? It is possible to consider skin complexion as an ordinal variable; consider whether retaining this ordering as in the dataset might be preferable to considering skin complexion as a categorical variable lacking order. \n",
    "\n",
    "**5.3** Is there a discernable trend in the incomes of participants from different regions/cities?\n",
    "\n",
    "**5.4** Is there a clear trend between BMI and the income?\n",
    "\n",
    "**5.5** Does the level of education show a clear trend with income? Is the trend similar across both levels of the \"gender\" variable available in this dataset?\n",
    "\n",
    "**5.6** Do any of the numeric attributes show a clear non-linear dependence with the amount of income?\n",
    "\n",
    "**5.7** Is the income lower or high for those living in 'nuclear' families?\n",
    "\n",
    "**5.8** What is the average effect of the 'Manglik' variable on income?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7be4db8-2c8f-437e-b016-659c755a08f1",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KNnTUgmwkWs5"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.1** Is there a disparity in income of participants by gender? Consider using a log scale or another technique to communicate clearly.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('data/Income_prediction.csv')\n",
    "df_2.columns\n",
    "\n",
    "def rename_var(df, col, var_dict):\n",
    "    new = 'n_' + col\n",
    "    df[new] = df[col]\n",
    "    for key,val in var_dict.items():\n",
    "        df.loc[df[col]==val,new] = key\n",
    "    return df\n",
    "\n",
    "df_2 = rename_var(df_2, 'gender', {'female':0, 'male':1})\n",
    "df_2 = rename_var(df_2, 'eating', {'Doesnt Matter':0, 'Jain': 1, 'Vegetarian': 2, 'Vegetarian With Eggs': 3, 'Non Vegetarian': 4})\n",
    "df_2 = rename_var(df_2, 'status', {'Doesnt Matter': 0, 'Middle Class': 1, 'Upper Middle Class': 2, 'High Class': 3, 'Rich / Affluent': 4})\n",
    "df_2 = rename_var(df_2, 'manglik', {'No': 0, 'Yes': 1, 'Do Not Know': 2})\n",
    "df_2 = rename_var(df_2, 'drinking', {'Doesnt Matter':0, 'No': 1, 'Occasionally': 2, 'Yes': 3})\n",
    "df_2 = rename_var(df_2, 'complexion',{'Very Fair ': 1, 'Fair ': 2, 'Wheatish ':3, 'Wheatish Medium ': 4, 'Dark':5})\n",
    "df_2 = rename_var(df_2, 'education',{'High School':0, 'Some college':1,'Undergrad':2, 'Grad':3, 'Doctorate':4})\n",
    "df_2 = rename_var(df_2, 'city',{'International': 1, 'Mumbai': 2, 'Delhi':3, 'Kolkata':4,'Bengaluru':5, 'Chennai':6, 'Hyderabad':7, 'Pune':8, 'Ahmedabad':9,'Surat':10, 'Vishakapatnam':11, 'Others':12})\n",
    "df_2 = rename_var(df_2, 'family_type',{'Doesnt Matter': 0, 'Others':3, 'Nuclear': 1, 'Joint family': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(xscale = 'log')\n",
    "sns.kdeplot(data=df_2[df_2.n_gender == 'male'], x = \"income\", ax = ax,\n",
    "           label = 'female')\n",
    "sns.kdeplot(data=df_2[df_2.n_gender == 'female'], x = \"income\", ax = ax, \n",
    "            color = 'orange', label = 'male')\n",
    "f.legend(loc = 'right')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "sns.boxplot(data=df_2, x = \"n_gender\", y = \"income\", ax = ax)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be somewhat of an income disparity. Generally each of the quartiles is lower for women than for men, and comparing the density function of each gender, there are more women below 10^4 than men, while there are more men making over 10^4 than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.2** Is there a relationship between income and the \"eating\" variable? Is there a relationship between income and skin complexion? It is possible to consider skin complexion as an ordinal variable; consider whether retaining this ordering as in the dataset might be preferable to considering skin complexion as a categorical variable lacking order.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here \n",
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "g = sns.boxplot(data=df_2, x = \"n_eating\", y = \"income\", ax = ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.legend(loc = 'upper right')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a big difference in incomes between vegetarain, vegetarian with eggs, and non-vegetarians. \"Doesn't matter\" diets have a higher minimum income but the other quartiles seem the same. There are fewer outliers at a highe income though. \n",
    "\n",
    "The biggest difference is for Jain diets. The income spead is smaller- the minimim is higher than for most other diets but the median and maximum are both lower and there are fewer outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "g = sns.boxplot(data=df_2, x = \"n_complexion\", y = \"income\", ax = ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.legend(loc = 'upper right')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the range and even the interquartile range is about the same for all complexions, the median gets higher and higher with lighter complexions. People with 'very fair' complexions have higher incomes in every quartile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.3",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.3** Is there a discernable trend in the incomes of participants from different regions/cities?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set()\n",
    "g = sns.barplot(data=df_2, x = \"n_city\", y = \"income\", ax = ax,\n",
    "               estimator = np.mean)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.legend(loc = 'upper right')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale='log')\n",
    "g = sns.boxplot(data=df_2, x = \"n_city\", y = \"income\", ax = ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.legend(loc = 'upper right')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities have a large difference in average income. There are many outliers for each city category so it is easier to interpret only looking at the mean or median and not the entire boxplot. \n",
    "\n",
    "'International', Bengaluru, Mumbai, Kolkata, and Deli have the highest mean incomes, wheras 'others', Surat, Vishakapatnam, and Ahmedabad have low mean incomes. Some areas have a much tighter distribution than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.4",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.4** Is there a clear trend between BMI and the income?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set()\n",
    "#sort bmi into bins\n",
    "df_2['bmi_bin'] = np.int64(df_2['bmi']/3)\n",
    "#drop the bins with too few people in them\n",
    "df_mod = df_2.loc[(df_2.bmi_bin>3)&(df_2.bmi_bin<11)]\n",
    "g = sns.barplot(data=df_mod, x = \"bmi_bin\", y = \"income\", ax = ax,\n",
    "               estimator = np.mean)\n",
    "ax.set_xlabel(\"BMI/3\")\n",
    "f.show()\n",
    "print(\"the number of people in each bin:\")\n",
    "df_2.groupby(by='bmi_bin').count()['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins 3,11,12,and 13 have too few people in them to consider. It seems that there is not a very strong relationship between BMI and income, although it does seem like having a BMI of ~12 or between ~21-24 is correlated with a higher mean income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.5",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.5** Does the level of education show a clear trend with income? Is the trend similar across both levels of the \"gender\" variable available in this dataset?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "g=sns.boxplot(data=df_2, x = \"n_education\", y = \"income\", ax = ax,\n",
    "           hue = 'n_gender')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.6",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.6** Do any of the numeric attributes show a clear non-linear dependence with the amount of income?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a higher level of education correlate with higher income for both women and men. For both genders there is not a big difference in income between people with some college and an undergraduate degree. In all cases, men earn more on average than women with the same education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.7",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.7** Is the income lower or high for those living in 'nuclear' families?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "g = sns.boxplot(data=df_2, x = \"n_family_type\", y = \"income\", ax = ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 75)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a big difference in income between those living in nuclear families and those living in joint or 'other' families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.8",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.8** What is the average effect of the 'Manglik' variable on income?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale = 'log')\n",
    "g=sns.boxplot(data=df_2, x = \"n_manglik\", y = \"income\", ax = ax)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no effect of the 'Manglik' variable on income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "47c47e2e-427f-408c-9384-a92fa779b3aa",
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 6:  Calculate the Gini Index [15 pts]</b>\n",
    "\n",
    "\n",
    "Gini coefficients are often used to quantify income inequality, read more [here](http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm).\n",
    "\n",
    "The Gini coefficient is defined by the formula:\n",
    "\n",
    "$G = \\dfrac{ \\sum_{i=1}^{n} (2i - n - 1) x_i}{n  \\sum_{i=1}^{n} x_i}$\n",
    "\n",
    "where $x$ is an observed value, $n$ is the number of values observed and $i$ is the rank of values in **ascending** order.\n",
    "\n",
    "A Gini Index of 0 implies perfect income equality, whereas a gini index close to 1 implies a concentration of wealth among the richest few.\n",
    "\n",
    "**6.1** Based on the above formula, calculate the Gini coffient for the income of the participants of this dataset\n",
    "\n",
    "**6.2** Compare your gini index with other countries.\n",
    "\n",
    "According to the [world bank estimate](https://www.indexmundi.com/facts/indicators/SI.POV.GINI/rankings) the gini index of South Africa is 0.6 while that of Ukrain is 0.25. \n",
    "\n",
    "Based on your calculated Gini index value for this dataset, what is your conclusion on the relationship of the income disparity in the three countries?\n",
    "\n",
    "Do the data source, self-report nature of the data, or sampling procedure affect your conclusions? If so, how?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "6.1",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**6.1** Based on the above formula, calculate the Gini coffient for the income of the participants of this dataset\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#number of observations\n",
    "n = df_2['income'].count()\n",
    "sum_income = df_2['income'].sum()\n",
    "\n",
    "#sort by income\n",
    "df_sorted = df_2.sort_values(by='income').reset_index()\n",
    "\n",
    "#assign a rank to each income\n",
    "income_vals = df_sorted['income'].unique()\n",
    "df_sorted['i'] = df_sorted.index\n",
    "df_sorted['gini_num'] = (2*df_sorted['i'] - n - 1)*df_sorted['income']\n",
    "gini_index = df_sorted['gini_num'].sum()/(n*sum_income)\n",
    "\n",
    "\n",
    "print(f'The Gini index of this dataset is {gini_index:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "6.2",
    "cell_id": "eaed1594-de29-4e01-aae5-b6a7f76f6303",
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kCMMuQiS652F",
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**6.2** Compare your gini index with other countries.\n",
    " \n",
    " According to the [world bank estimate](https://www.indexmundi.com/facts/indicators/SI.POV.GINI/rankings) the gini index of South Africa is 0.6 while that of Ukrain is 0.25.\n",
    " \n",
    " Based on your calculated Gini index value for this dataset, what is your conclusion on the relationship of the income disparity in the three countries?\n",
    " \n",
    " Do the data source, self-report nature of the data, or sampling procedure affect your conclusions? If so, how?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The world bank reports that the Gini index of India is 0.37, whereas the index from this dataset is 0.5. Since we are not looking at the entire population of India, it is not surprising that there is some difference between them.\n",
    "\n",
    "It seems that the people in this dataset have a greater income disparity than Ukrain does but a lower income disparity than Sourth Africa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b3ed64a-92ac-482f-8f1d-bd1c6cbf772b",
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 7 (for 209a students, optional for others):  Multi-Linear Regression [10 pts]</b>\n",
    "\n",
    "Now we increase the scope of our analysis to solve another problem that is related to income of the participants.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9de3ea4c-961f-46c0-b308-febe73da6df0",
    "deletable": false,
    "editable": false
   },
   "source": [
    "![](https://github.com/hargun3045/blog-dump/blob/master/modi.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d6f44620-e4b1-447d-841c-185066aae37f",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Owing to a large number of people underreporting their income to evade taxes, the Income Tax Department of India wants you, an esteemed data scientist, to build a machine learning model that can predict the income of a given tax-payer based on commonly available information.\n",
    "\n",
    "This will help the department red flag suspected individuals who may show discernable trends of earing high values of income but are excessively under-reporting on their annual income.\n",
    "\n",
    "The goal is to build the best model with the given dataset, using both categorical and continuous predictors that are available.\n",
    "\n",
    "As with all other homework problems, this is a learning exercise; in the real world, it is your decision to choose the types of data science projects you will work on as well as which clients you will work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8edf8b8b-f950-4745-a886-2e991e6185cc",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Fit a multiple linear regression model to the training set.\n",
    "Use the `sklearn` library.\n",
    "\n",
    "#### Deliverables\n",
    "Your code should be contained in a Jupyter notebook cell.  An appropriate level of comments is necessary.  Your code should run and output the required outputs described below.\n",
    "\n",
    "#### Required Outputs\n",
    "- Fit a multiple linear regression model on the training set\n",
    "- Predict on train and test sets\n",
    "- Calculate the MSE for the train & test set\n",
    "- Report the $R^2$ score on the test set.\n",
    "- Make a plot of Residuals vs Log of predicted values $\\hat{y}$, with residuals on the $Y$-axis and predicted values on the $X$-axis. Use the formula ${\\epsilon} = y - \\hat{y}$ to compute the residual values. Include a horizontal line denoting the zero residual value on the $Y$-axis.\n",
    "- Plot a histogram of the magnitudes of the residuals.\n",
    "\n",
    "#### Optional Outputs\n",
    "You are encouraged to experiment with ways to improve your model *after first reporting results with only the required outputs*. Some ideas are given below:\n",
    "- Polynomial terms for continous variables\n",
    "- Interaction terms between variables\n",
    "- Feature selection among given predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "We should do this together!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
